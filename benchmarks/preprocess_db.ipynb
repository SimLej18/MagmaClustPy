{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Benchmarks - Preprocess DB\n",
    "\n",
    "**Main considerations when implementing Preprocess DB**\n",
    "\n",
    "Magma and MagmaClust both work on unaligned sequences of varying sizes.\n",
    "Yet, we want to be able to perform as many operations in a vectorisable and jittable way.\n",
    "\n",
    "This mean that we need to pad the sequences to the same length, aligning them in the process, and then mask the padded values.\n",
    "A mask should be computed at the first step of the process to not be re-computed every time we need to mask the values.\n",
    "\n",
    "This way, each operation can have custom logic to handle padded values, all while preserving vectorisation and jitting.\n"
   ],
   "id": "3169657593ef2b05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Setup"
   ],
   "id": "7b65ff45bca2668a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:13.490758Z",
     "start_time": "2025-06-19T13:51:13.488139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standard library\n",
    "import os\n",
    "\n",
    "# Config\n",
    "# os.environ['JAX_ENABLE_X64'] = \"True\""
   ],
   "id": "cb9dc5bf24ca0bfc",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:13.511168Z",
     "start_time": "2025-06-19T13:51:13.508197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Third party\n",
    "import jax\n",
    "from jax import vmap, jit\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize random key\n",
    "key = jax.random.PRNGKey(41)"
   ],
   "id": "17394bcba5a0c15f",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:13.527621Z",
     "start_time": "2025-06-19T13:51:13.525861Z"
    }
   },
   "cell_type": "code",
   "source": "# Local\n",
   "id": "1d8411a9b05f7d1b",
   "outputs": [],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:13.544803Z",
     "start_time": "2025-06-19T13:51:13.541978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set constants\n",
    "M = 500  # Number of sequences\n",
    "MIN_N = 50  # Minimum sequence length\n",
    "MAX_N = 100  # Maximum sequence length\n",
    "grid = jnp.arange(-500., 500., dtype=jnp.float32)  # Grid to pick inputs from"
   ],
   "id": "8fdfe2743b68b3bf",
   "outputs": [],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:13.560634Z",
     "start_time": "2025-06-19T13:51:13.558322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "# Smaller constants for testing\n",
    "M = 4  # Number of sequences\n",
    "MIN_N = 2  # Minimum sequence length\n",
    "MAX_N = 5  # Maximum sequence length\n",
    "grid = jnp.arange(5, 10, 1, dtype=jnp.float64)  # Grid to pick inputs from\n",
    "\"\"\""
   ],
   "id": "ba38ac117e84fd2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Smaller constants for testing\\nM = 4  # Number of sequences\\nMIN_N = 2  # Minimum sequence length\\nMAX_N = 5  # Maximum sequence length\\ngrid = jnp.arange(5, 10, 1, dtype=jnp.float64)  # Grid to pick inputs from\\n'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Data"
   ],
   "id": "9e456a3079c6f8e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:13.579483Z",
     "start_time": "2025-06-19T13:51:13.576472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_dummy_db(M: int, MIN_N: int, MAX_N: int, grid: jnp.array, key: jnp.array):\n",
    "\t# We fill DB with random sequences\n",
    "\tdata = []\n",
    "\tfor m in range(M):\n",
    "\t\tkey, subkey = jax.random.split(key)\n",
    "\t\tn_points = jax.random.randint(subkey, (), MIN_N, MAX_N)\n",
    "\t\tinputs = jax.random.choice(subkey, grid, (n_points,), replace=False)\n",
    "\t\tfor n, i in zip(range(n_points), inputs):\n",
    "\t\t\tkey, subkey1, subkey2 = jax.random.split(key, 3)\n",
    "\t\t\tdata.append({\n",
    "\t\t\t\t\"ID\": m,\n",
    "\t\t\t\t\"Input\": i.item(),\n",
    "\t\t\t\t\"Output\": jax.random.uniform(subkey2, (), jnp.float32, -5, 5).item()\n",
    "\t\t\t})\n",
    "\treturn pd.DataFrame(data)"
   ],
   "id": "4479d9ad50c33957",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:16.534422Z",
     "start_time": "2025-06-19T13:51:13.596715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = generate_dummy_db(M, MIN_N, MAX_N, grid, key)\n",
    "db"
   ],
   "id": "b94e73cc71065744",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        ID  Input    Output\n",
       "0        0 -142.0  0.144109\n",
       "1        0 -173.0  0.106797\n",
       "2        0 -113.0  1.152955\n",
       "3        0 -441.0 -3.174350\n",
       "4        0 -375.0  1.230059\n",
       "...    ...    ...       ...\n",
       "37056  499 -136.0  1.238136\n",
       "37057  499  394.0  1.993368\n",
       "37058  499  289.0  1.425520\n",
       "37059  499 -182.0 -1.829005\n",
       "37060  499  385.0  1.328452\n",
       "\n",
       "[37061 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-142.0</td>\n",
       "      <td>0.144109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>0.106797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-113.0</td>\n",
       "      <td>1.152955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-441.0</td>\n",
       "      <td>-3.174350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-375.0</td>\n",
       "      <td>1.230059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37056</th>\n",
       "      <td>499</td>\n",
       "      <td>-136.0</td>\n",
       "      <td>1.238136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37057</th>\n",
       "      <td>499</td>\n",
       "      <td>394.0</td>\n",
       "      <td>1.993368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37058</th>\n",
       "      <td>499</td>\n",
       "      <td>289.0</td>\n",
       "      <td>1.425520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37059</th>\n",
       "      <td>499</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-1.829005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37060</th>\n",
       "      <td>499</td>\n",
       "      <td>385.0</td>\n",
       "      <td>1.328452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37061 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Current implementation"
   ],
   "id": "fc6f59bda2ecbaad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:16.571720Z",
     "start_time": "2025-06-19T13:51:16.565615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Uses .values for even faster iteration\n",
    "@jit\n",
    "def extract_id_data(_id, values, all_inputs):\n",
    "\t\"\"\"\n",
    "\tExtract data for a given ID from the values array and return a row of padded inputs, padded outputs and mask.\n",
    "\n",
    "\t:param _id:\n",
    "\t:param id_index:\n",
    "\t:param values:\n",
    "\t:param all_inputs:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tpadded_input = jnp.full((len(all_inputs),), jnp.nan)\n",
    "\tpadded_output = jnp.full((len(all_inputs),), jnp.nan)\n",
    "\tmask = jnp.zeros((len(all_inputs),), dtype=bool)\n",
    "\n",
    "\tidx = jnp.searchsorted(all_inputs, jnp.where(values[:, 0] == _id, values[:, 1], jnp.nan))\n",
    "\n",
    "\treturn padded_input.at[idx].set(values[:, 1]), padded_output.at[idx].set(values[:, 2]), mask.at[idx].set(True)\n",
    "\n",
    "\n",
    "def preprocess_db(db: pd.DataFrame):\n",
    "\t\"\"\"\n",
    "\n",
    "\t:param db: the db to process, with columns \"ID\", \"Input\" and \"Output\", in that order\n",
    "\t:return: a tuple of (all_inputs, padded_inputs, padded_outputs, masks)\n",
    "\t   - all_inputs: a matrix of shape (P, ) with all distinct inputs\n",
    "\t   - padded_inputs: a matrix of shape (M, P) where M is the number of sequences and P is the number of distinct\n",
    "\t   inputs. Missing inputs for each sequence are represented as NaNs.\n",
    "\t   - padded_outputs: a matrix of shape (M, P) with corresponding output for each input and NaNs for missing inputs\n",
    "\t   - masks: a matrix of shape (M, P) with 1 where the input is valid and 0 where it is padded\n",
    "\t\"\"\"\n",
    "\t# Get all distinct inputs\n",
    "\tall_ids = jnp.array(db[\"ID\"].unique())\n",
    "\tall_inputs = jnp.sort(jnp.array(db[\"Input\"].unique()))\n",
    "\n",
    "\t# Initialise padded inputs, padded outputs and masks\n",
    "\tpadded_inputs, padded_outputs, masks = vmap(extract_id_data, in_axes=(0, None, None))(all_ids, db[\n",
    "\t\t[\"ID\", \"Input\", \"Output\"]].values, all_inputs)\n",
    "\n",
    "\treturn all_inputs, padded_inputs, padded_outputs, masks"
   ],
   "id": "6c0128fd558881fa",
   "outputs": [],
   "execution_count": 184
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Custom implementation(s)"
   ],
   "id": "aca844690354fcc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Defaults we wish to fix:\n",
    "\n",
    "For M individuals, each having between MIN_N and MAX_N observations over a grid of size G, we currently pad the inputs to the size of the union of all distinct inputs, named P. With a big M, P is likely to approach G, even though MAX_N is much smaller than G.\n",
    "\n",
    "Later in the process, this leads to inversion of huge padded matrices. As those matrices are padded with identity vectors, the inversion in itself is not made terribly worse. However, the memory footprint is much larger than it needs to be, and the movement of data in and out of the GPU is much more costly.\n",
    "\n",
    "Rather than \"aligning\" the inputs to the union of distinct inputs, we can just compute the indices of the inputs in the grid, and use those indices to map individual inputs/covariance matrices/precision matrices to the grid when needed. By filling indices whith nans for smaller sequences, we ensure they can still be processed in a vectorised way, while limiting the memory footprint to it's theoretical minimum.\n",
    "\n",
    "In this approach, we don't carry a mask arround, but only a mapping of indices to inputs in the distinct inputs grid. This mapping is used to compute the covariance matrices."
   ],
   "id": "dfd6141192b611cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:16.606624Z",
     "start_time": "2025-06-19T13:51:16.600230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def extract_id_data_new(_id, values, all_inputs, to_fill):\n",
    "\t\"\"\"\n",
    "\tExtract data for a given ID from the values array and return a row of padded inputs, padded outputs and index_mappings.\n",
    "\n",
    "\t:param _id:\n",
    "\t:param id_index:\n",
    "\t:param values:\n",
    "\t:param all_inputs:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tinputs_i = jnp.where(values[:,0] == _id, values[:,1], jnp.nan)\n",
    "\toutputs_i = jnp.where(values[:,0] == _id, values[:,2], jnp.nan)\n",
    "\tmappings_i = jnp.searchsorted(all_inputs, inputs_i)\n",
    "\n",
    "\t# Compute index among the whole dataset\n",
    "\tidx_i = jnp.where(jnp.isnan(inputs_i), to_fill.shape[0] + 1, jnp.cumsum(~jnp.isnan(inputs_i)) - 1)\n",
    "\n",
    "\t# Create padded inputs and outputs\n",
    "\tpadded_input = jnp.full(to_fill.shape[0], jnp.nan).at[idx_i].set(inputs_i)\n",
    "\tpadded_output = jnp.full(to_fill.shape[0], jnp.nan).at[idx_i].set(outputs_i)\n",
    "\tindex_mappings = jnp.full(to_fill.shape[0], all_inputs.shape[0] + 1).at[idx_i].set(mappings_i).astype(int)\n",
    "\n",
    "\treturn padded_input, padded_output, index_mappings\n",
    "\n",
    "\n",
    "def preprocess_db_new(db: pd.DataFrame):\n",
    "\t\"\"\"\n",
    "\n",
    "\t:param db: the db to process, with columns \"ID\", \"Input\" and \"Output\", in that order\n",
    "\t:return: a tuple of (all_inputs, padded_inputs, padded_outputs, masks)\n",
    "\t   - all_inputs: a matrix of shape (P, ) with all distinct inputs\n",
    "\t   - padded_inputs: a matrix of shape (M, MAX_N) where M is the number of sequences and MAX_N is the max number of points among all sequences. Missing inputs for each sequence are represented as NaNs.\n",
    "\t   - padded_outputs: a matrix of shape (M, MAX_N) with corresponding output for each input and NaNs for missing inputs\n",
    "\t   - index_mappings: a matrix of shape (M, MAX_N) with indices of the inputs in the all_inputs array. Missing inputs for each sequence are represented as -1.\n",
    "\t\"\"\"\n",
    "\t# Get all distinct inputs\n",
    "\tdb_sorted = db.sort_values(['ID', 'Input'])\n",
    "\tall_ids = jnp.array(db_sorted[\"ID\"].unique())\n",
    "\tall_inputs = jnp.sort(jnp.array(db_sorted[\"Input\"].unique()))\n",
    "\tMAX_N = db_sorted.groupby(\"ID\")[\"Input\"].count().max()  # Maximum number of points in a sequence\n",
    "\tto_fill = jnp.full((MAX_N), jnp.nan)  # Placeholder for padded inputs and outputs\n",
    "\n",
    "\t# Initialise padded inputs, padded outputs and masks\n",
    "\tpadded_inputs, padded_outputs, index_mappings = vmap(extract_id_data_new, in_axes=(0, None, None, None))(all_ids,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t db_sorted[\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t [\"ID\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \"Input\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \"Output\"]].values,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t all_inputs,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t to_fill)\n",
    "\n",
    "\treturn all_inputs, padded_inputs, padded_outputs, index_mappings"
   ],
   "id": "f8735bdf33e0e901",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Comparison"
   ],
   "id": "e36d61be045a06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:16.700990Z",
     "start_time": "2025-06-19T13:51:16.631883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_inputs, padded_inputs, padded_outputs, masks = preprocess_db(db)\n",
    "all_inputs.shape, padded_inputs.shape, padded_outputs.shape, masks.shape"
   ],
   "id": "7f350e2e3f6d3a1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (500, 1000), (500, 1000), (500, 1000))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:16.871719Z",
     "start_time": "2025-06-19T13:51:16.709542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_inputs_new, padded_inputs_new, padded_outputs_new, index_mappings_new = preprocess_db_new(db)\n",
    "all_inputs_new.shape, padded_inputs_new.shape, padded_outputs_new.shape, index_mappings_new.shape"
   ],
   "id": "3713d5657c77b9e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (500, 99), (500, 99), (500, 99))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:17.198969Z",
     "start_time": "2025-06-19T13:51:17.196965Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"{len(all_inputs)} distinct inputs, covering {len(all_inputs) / len(grid) * 100:.2f}% of the grid\")",
   "id": "f0edd4a4348a9fa2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 distinct inputs, covering 100.00% of the grid\n"
     ]
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:17.220034Z",
     "start_time": "2025-06-19T13:51:17.218367Z"
    }
   },
   "cell_type": "code",
   "source": "#jnp.allclose(all_inputs, all_inputs_new), jnp.allclose(padded_inputs, padded_inputs_new, equal_nan=True), jnp.allclose(padded_outputs, padded_outputs_new, equal_nan=True), jnp.allclose(masks, masks_new)",
   "id": "df2007807106b790",
   "outputs": [],
   "execution_count": 189
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e7851b3f9041e892"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Performance comparison on dummy tasks",
   "id": "d861d5209304775f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Covariance matrix computation",
   "id": "654da64f3d4dd69b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:17.236155Z",
     "start_time": "2025-06-19T13:51:17.234005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from MagmaClustPy.kernels import RBFKernel\n",
    "\n",
    "kern = RBFKernel(length_scale=jnp.array(0.3), variance=jnp.array(1.))"
   ],
   "id": "7ce3973744e48ec0",
   "outputs": [],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:17.256369Z",
     "start_time": "2025-06-19T13:51:17.250135Z"
    }
   },
   "cell_type": "code",
   "source": "padded_inputs[0], padded_inputs_new[0], index_mappings_new[0]",
   "id": "88176ab9ec6b770e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([  nan,   nan,   nan,   nan, -496.,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan, -468.,   nan,   nan,   nan,\n",
       "          nan,   nan, -462.,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan, -441.,   nan,   nan,   nan,\n",
       "          nan,   nan, -435.,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan, -417., -416.,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan, -397.,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan, -375.,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan, -334.,   nan,   nan,   nan,   nan,\n",
       "        -329.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan, -306.,   nan,   nan,   nan,\n",
       "        -302., -301.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan, -277.,   nan,\n",
       "          nan, -274.,   nan,   nan,   nan,   nan, -269.,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan, -234.,   nan,   nan,   nan,\n",
       "          nan, -229.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan, -181.,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan, -173., -172.,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan, -160.,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan, -142., -141.,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan, -134.,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan, -126.,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "        -113.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,  -90.,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,  -62.,   nan,   nan,\n",
       "          nan,  -58.,  -57.,   nan,  -55.,   nan,   nan,   nan,   nan,\n",
       "          nan,  -49.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         -32.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,  -22.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,  -10.,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   25.,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   54.,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   75.,\n",
       "          nan,   77.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   96.,   97.,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,  120.,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,  136.,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,  149.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,  158.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,  196.,  197.,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,  213.,   nan,   nan,   nan,   nan,  218.,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,  225.,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,  233.,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,  253.,  254.,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,  262.,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         310.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,  320.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,  340.,   nan,   nan,  343.,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,  388.,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,  411.,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,  479.,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,  489.,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,  498.,\n",
       "          nan], dtype=float32, weak_type=True),\n",
       " Array([-496., -468., -462., -441., -435., -417., -416., -397., -375.,\n",
       "        -334., -329., -306., -302., -301., -277., -274., -269., -234.,\n",
       "        -229., -181., -173., -172., -160., -142., -141., -134., -126.,\n",
       "        -113.,  -90.,  -62.,  -58.,  -57.,  -55.,  -49.,  -32.,  -22.,\n",
       "         -10.,   25.,   54.,   75.,   77.,   96.,   97.,  120.,  136.,\n",
       "         149.,  158.,  196.,  197.,  213.,  218.,  225.,  233.,  253.,\n",
       "         254.,  262.,  310.,  320.,  340.,  343.,  388.,  411.,  479.,\n",
       "         489.,  498.,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "          nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan],      dtype=float32, weak_type=True),\n",
       " Array([   4,   32,   38,   59,   65,   83,   84,  103,  125,  166,  171,\n",
       "         194,  198,  199,  223,  226,  231,  266,  271,  319,  327,  328,\n",
       "         340,  358,  359,  366,  374,  387,  410,  438,  442,  443,  445,\n",
       "         451,  468,  478,  490,  525,  554,  575,  577,  596,  597,  620,\n",
       "         636,  649,  658,  696,  697,  713,  718,  725,  733,  753,  754,\n",
       "         762,  810,  820,  840,  843,  888,  911,  979,  989,  998, 1001,\n",
       "        1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001,\n",
       "        1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001,\n",
       "        1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001],      dtype=int32))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:17.273983Z",
     "start_time": "2025-06-19T13:51:17.271713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def map_to_full_cov(dense_cov, all_inputs, mapping):\n",
    "\t# return jnp.full((len(all_inputs), len(all_inputs)), jnp.nan).at[tuple(jnp.meshgrid(mapping, mapping))].set(dense_cov)\n",
    "\treturn jnp.full((len(all_inputs), len(all_inputs)), jnp.nan).at[jnp.ix_(mapping, mapping)].set(dense_cov)"
   ],
   "id": "1e60e709debe86",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:17.288898Z",
     "start_time": "2025-06-19T13:51:17.286950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def map_to_full_batch(dense_covs, all_inputs, mappings):\n",
    "    return vmap(map_to_full_cov, in_axes=(0, None, 0))(dense_covs, all_inputs, mappings)"
   ],
   "id": "a697fe2c5d388c2d",
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:17.306509Z",
     "start_time": "2025-06-19T13:51:17.303124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# On single input\n",
    "np.asarray(kern(padded_inputs[0]))"
   ],
   "id": "ce9c541fd82931b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan,  1., nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:17.373671Z",
     "start_time": "2025-06-19T13:51:17.347549Z"
    }
   },
   "cell_type": "code",
   "source": "np.asarray(map_to_full_cov(kern(padded_inputs_new[0]), all_inputs, index_mappings_new[0]))",
   "id": "17f4e3177a55e9e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan,  1., nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:17.523595Z",
     "start_time": "2025-06-19T13:51:17.519331Z"
    }
   },
   "cell_type": "code",
   "source": "jnp.allclose(kern(padded_inputs[0]), map_to_full_cov(kern(padded_inputs_new[0]), all_inputs, index_mappings_new[0]), equal_nan=True)",
   "id": "a3cda181997d9435",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:19.914997Z",
     "start_time": "2025-06-19T13:51:17.658336Z"
    }
   },
   "cell_type": "code",
   "source": "%timeit kern(padded_inputs[0]).block_until_ready()",
   "id": "99b582cdb58d986a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276 μs ± 12.8 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:22.936539Z",
     "start_time": "2025-06-19T13:51:19.949770Z"
    }
   },
   "cell_type": "code",
   "source": "%timeit map_to_full_cov(kern(padded_inputs_new[0]), all_inputs, index_mappings_new[0]).block_until_ready()",
   "id": "399bb3e6664213a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 μs ± 13 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:23.218612Z",
     "start_time": "2025-06-19T13:51:22.953190Z"
    }
   },
   "cell_type": "code",
   "source": "a = kern(padded_inputs).block_until_ready()",
   "id": "c0d671a58d1ebd8a",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:23.605877Z",
     "start_time": "2025-06-19T13:51:23.233805Z"
    }
   },
   "cell_type": "code",
   "source": "b = map_to_full_batch(kern(padded_inputs_new), all_inputs, index_mappings_new).block_until_ready()",
   "id": "8024476cde0c8f59",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:24.596075Z",
     "start_time": "2025-06-19T13:51:23.621958Z"
    }
   },
   "cell_type": "code",
   "source": "jnp.allclose(a, b, equal_nan=True)",
   "id": "66099c2b7ac21896",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:25.515236Z",
     "start_time": "2025-06-19T13:51:24.636189Z"
    }
   },
   "cell_type": "code",
   "source": "%timeit kern(padded_inputs).block_until_ready()",
   "id": "5bd49ace6d0da8f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.9 ms ± 23.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:38.254955Z",
     "start_time": "2025-06-19T13:51:25.531756Z"
    }
   },
   "cell_type": "code",
   "source": "%timeit map_to_full_batch(kern(padded_inputs_new), all_inputs, index_mappings_new).block_until_ready()",
   "id": "f1ba452d855f457c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 ms ± 5.88 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "execution_count": 203
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sum of invs",
   "id": "a5c08274d94af762"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:38.280773Z",
     "start_time": "2025-06-19T13:51:38.274915Z"
    }
   },
   "cell_type": "code",
   "source": "from jax.scipy.linalg import cho_factor, cho_solve",
   "id": "2efe142c8ab04daf",
   "outputs": [],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:38.310335Z",
     "start_time": "2025-06-19T13:51:38.307139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def full_pad_sum_of_inv(inputs, masks, all_inputs, kernel):\n",
    "\t\"\"\"\n",
    "\tcompute the sum of inverses of all cross-covariance matrices for each input in inputs.\n",
    "\tIt uses a full padding approach, where the inputs are padded to the size of all_inputs and aligned.\n",
    "\tmasks gives indices where the inputs are valid (True) or padded (False).\n",
    "\n",
    "\t:param inputs:\n",
    "\t:param masks:\n",
    "\t:param all_inputs:\n",
    "\t:param kernel:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tnugget = 1e-8  # Small value to ensure numerical stability\n",
    "\tcovs = kernel(inputs)\n",
    "\n",
    "\tsmall_eye = jnp.broadcast_to(jnp.eye(covs.shape[-1]), covs.shape)\n",
    "\n",
    "\t# covs is padded with NaNs. Replace them by their corresponding identity rows/cols\n",
    "\tmasks_2D = masks[:, :, None] & masks[:, None, :]\n",
    "\tcovs = jnp.where(masks_2D, covs, small_eye)\n",
    "\n",
    "\tcovs_U, _ = cho_factor(covs + small_eye * nugget)\n",
    "\tcovs_inv = cho_solve((covs_U, False), small_eye)\n",
    "\tcovs_inv -= jnp.where(masks_2D, 0, small_eye)  # Correction on the diagonal\n",
    "\treturn covs_inv.sum(axis=0)"
   ],
   "id": "be883cb5cc43cf6e",
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:38.331588Z",
     "start_time": "2025-06-19T13:51:38.329186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def dense_pad_sum_of_inv(inputs, mappings, all_inputs, kernel):\n",
    "\t\"\"\"\n",
    "\tcompute the sum of inverses of all cross-covariance matrices for each input in inputs.\n",
    "\tIt uses a dense padding approach, where the inputs are padded to the size of MAX_N and not aligned. Their positions in the all_inputs array are given by mappings.\n",
    "\n",
    "\t:param inputs:\n",
    "\t:param mappings:\n",
    "\t:param all_inputs:\n",
    "\t:param kernel:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tnugget = 1e-8  # Small value to ensure numerical stability\n",
    "\tcovs = kernel(inputs)\n",
    "\n",
    "\tsmall_eye = jnp.broadcast_to(jnp.eye(covs.shape[-1]), covs.shape)\n",
    "\n",
    "\t# Some covs may still end with a few NaNs, so we replace them by their corresponding identity rows/cols\n",
    "\teyed_covs = jnp.where(jnp.isnan(covs), small_eye, covs)\n",
    "\n",
    "\tcovs_U, _ = cho_factor(eyed_covs + small_eye * nugget)\n",
    "\tcovs_inv = cho_solve((covs_U, False), small_eye)\n",
    "\tcovs_inv -= jnp.where(jnp.isnan(covs), small_eye, 0)  # Correction on the diagonal\n",
    "\n",
    "\t# Now we need to map the covs_inv to the all_inputs array\n",
    "\treturn jnp.nan_to_num(map_to_full_batch(covs_inv, all_inputs, mappings)).sum(axis=0)"
   ],
   "id": "86504666de43cec7",
   "outputs": [],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:38.431669Z",
     "start_time": "2025-06-19T13:51:38.346637Z"
    }
   },
   "cell_type": "code",
   "source": "a = full_pad_sum_of_inv(padded_inputs, masks, all_inputs, kern)",
   "id": "5becbbae00b92369",
   "outputs": [],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:51:44.369650Z",
     "start_time": "2025-06-19T13:51:44.252143Z"
    }
   },
   "cell_type": "code",
   "source": "b = dense_pad_sum_of_inv(padded_inputs_new, index_mappings_new, all_inputs, kern)",
   "id": "306661bd098cc0f9",
   "outputs": [],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:53:39.831232Z",
     "start_time": "2025-06-19T13:53:39.826588Z"
    }
   },
   "cell_type": "code",
   "source": "jnp.allclose(a, b, equal_nan=True, atol=1e-6)",
   "id": "d86bee5056fd5d63",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:52:19.406676Z",
     "start_time": "2025-06-19T13:51:44.698870Z"
    }
   },
   "cell_type": "code",
   "source": "%timeit full_pad_sum_of_inv(padded_inputs, masks, all_inputs, kern).block_until_ready()",
   "id": "5e516fdd819a11a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28 s ± 32 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T13:52:21.523694Z",
     "start_time": "2025-06-19T13:52:19.496922Z"
    }
   },
   "cell_type": "code",
   "source": "%timeit dense_pad_sum_of_inv(padded_inputs_new, index_mappings_new, all_inputs, kern).block_until_ready()",
   "id": "fa10b290263f2766",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 ms ± 5.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "execution_count": 211
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
