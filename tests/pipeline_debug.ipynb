{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pipeline debug notebook\n",
    "\n",
    "This notebook allows for tests and debugging inside the whole codebase of MagmaClutPy.\n",
    "\n",
    "It removes optimisations like jax.jit and computes on 32-bit floats to allow for easier debugging and testing.\n",
    "\n",
    "---"
   ],
   "id": "962c768d99835097"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "b0ebee4717940c77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:17.326198Z",
     "start_time": "2025-06-16T11:14:17.322374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "USE_JIT = False\n",
    "USE_X64 = False\n",
    "DEBUG_NANS = False"
   ],
   "id": "9b92c50e601eef83",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.157240Z",
     "start_time": "2025-06-16T11:14:17.428570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standard imports\n",
    "import os\n",
    "if USE_X64:\n",
    "\tos.environ['JAX_ENABLE_X64'] = \"True\"\n",
    "\n",
    "import time\n",
    "from typing import NamedTuple\n",
    "\n",
    "# JAX imports\n",
    "import jax\n",
    "jax.config.update(\"jax_disable_jit\", not USE_JIT)\n",
    "jax.config.update(\"jax_debug_nans\", DEBUG_NANS)\n",
    "from jax import vmap, jit\n",
    "from jax.lax import cond\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "from jax.scipy.linalg import cho_solve, cho_factor\n",
    "from jax.scipy.optimize import minimize\n",
    "from jax.scipy.stats.multivariate_normal import logpdf\n",
    "from jax.tree_util import register_pytree_node_class, tree_flatten\n",
    "import chex\n",
    "import optax\n",
    "import optax.tree_utils as otu\n",
    "\n",
    "# Pandas import\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "7068ce6d2aa8e01d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "4f52c155c14104fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "ebeb98a29ae78a02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.165684Z",
     "start_time": "2025-06-16T11:14:18.163945Z"
    }
   },
   "cell_type": "code",
   "source": "# from MagmaClustPy.utils import preprocess_db",
   "id": "d8327008ae14a019",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.179829Z",
     "start_time": "2025-06-16T11:14:18.176822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_db(db: pd.DataFrame):\n",
    "\t\"\"\"\n",
    "\n",
    "\t:param db: the db to process, with columns \"ID\", \"Input\" and \"Output\"\n",
    "\t:return: a tuple of (all_inputs, padded_inputs, padded_outputs, masks)\n",
    "\t   - all_inputs: a matrix of shape (P, ) with all distinct inputs\n",
    "\t   - padded_inputs: a matrix of shape (M, P) where M is the number of sequences and P is the number of distinct\n",
    "\t   inputs. Missing inputs for each sequence are represented as NaNs.\n",
    "\t   - padded_outputs: a matrix of shape (M, P) with corresponding output for each input and NaNs for missing inputs\n",
    "\t   - masks: a matrix of shape (M, P) with 1 where the input is valid and 0 where it is padded\n",
    "\t\"\"\"\n",
    "\t# Get all distinct inputs\n",
    "\tall_ids = jnp.array(db[\"ID\"].unique())\n",
    "\tall_inputs = jnp.sort(jnp.array(db[\"Input\"].unique()))\n",
    "\n",
    "\t# Initialise padded inputs, padded outputs and masks\n",
    "\tpadded_inputs = jnp.full((len(all_ids), len(all_inputs)), jnp.nan)\n",
    "\tpadded_outputs = jnp.full((len(all_ids), len(all_inputs)), jnp.nan)\n",
    "\tmasks = jnp.zeros((len(all_ids), len(all_inputs)), dtype=bool)\n",
    "\n",
    "\t# Fill padded inputs, padded outputs and masks\n",
    "\tprev_id = \"\"\n",
    "\tid_index = -1\n",
    "\n",
    "\tfor row, _id, input, output in db[[\"ID\", \"Input\", \"Output\"]].itertuples():\n",
    "\t\tif _id != prev_id:\n",
    "\t\t\tprev_id = _id\n",
    "\t\t\tid_index += 1\n",
    "\n",
    "\t\tidx = jnp.searchsorted(all_inputs, input)\n",
    "\t\tpadded_inputs = padded_inputs.at[id_index, idx].set(input)\n",
    "\t\tpadded_outputs = padded_outputs.at[id_index, idx].set(output)\n",
    "\t\tmasks = masks.at[id_index, idx].set(True)\n",
    "\n",
    "\treturn all_inputs, padded_inputs, padded_outputs, masks"
   ],
   "id": "63602987d560d597",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "242ba5e7c3fb9bd8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Kernels",
   "id": "71ef856c3de468d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.196733Z",
     "start_time": "2025-06-16T11:14:18.194633Z"
    }
   },
   "cell_type": "code",
   "source": "# from MagmaClustPy.kernels import SEMagmaKernel, NoisySEMagmaKernel",
   "id": "6523b09a1f98d2c5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.219963Z",
     "start_time": "2025-06-16T11:14:18.212701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@register_pytree_node_class\n",
    "class AbstractKernel:\n",
    "\tdef __init__(self, skip_check=False, **kwargs):\n",
    "\t\tif not skip_check:\n",
    "\t\t\t# Check that hyperparameters are all jnp arrays/scalars or kernels\n",
    "\t\t\tfor key, value in kwargs.items():\n",
    "\t\t\t\tif not isinstance(value, jnp.ndarray):  # Check type\n",
    "\t\t\t\t\tkwargs[key] = jnp.array(value)\n",
    "\t\t\t\tif len(kwargs[key].shape) > 1:  # Check dimensionality\n",
    "\t\t\t\t\traise ValueError(f\"Parameter {key} must be a scalar or a 1D array, got shape {value.shape}.\")\n",
    "\n",
    "\t\t# Register hyperparameters in *kwargs* as instance attributes\n",
    "\t\tself.__dict__.update(kwargs)\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\treturn f\"{self.__class__.__name__}({', '.join([f'{key}={value}' for key, value in self.__dict__.items()])})\"\n",
    "\n",
    "\tdef __repr__(self):\n",
    "\t\treturn str(self)\n",
    "\n",
    "\t@jit\n",
    "\tdef check_kwargs(self, **kwargs):\n",
    "\t\tfor key in self.__dict__:\n",
    "\t\t\tif key not in kwargs:\n",
    "\t\t\t\tkwargs[key] = self.__dict__[key]\n",
    "\t\treturn kwargs\n",
    "\n",
    "\t@jit\n",
    "\tdef __call__(self, x1, x2=None, **kwargs):\n",
    "\t\t# If no x2 is provided, we compute the covariance between x1 and itself\n",
    "\t\tif x2 is None:\n",
    "\t\t\tx2 = x1\n",
    "\n",
    "\t\t# Check kwargs\n",
    "\t\tkwargs = self.check_kwargs(**kwargs)\n",
    "\n",
    "\t\t# Call the appropriate method\n",
    "\t\tif jnp.isscalar(x1) and jnp.isscalar(x2):\n",
    "\t\t\treturn self.compute_scalar_if_not_nan(x1, x2, **kwargs)\n",
    "\t\telif jnp.ndim(x1) == 1 and jnp.isscalar(x2):\n",
    "\t\t\treturn self.compute_vector_if_not_nan(x1, x2, **kwargs)\n",
    "\t\telif jnp.isscalar(x1) and jnp.ndim(x2) == 1:\n",
    "\t\t\treturn self.compute_vector_if_not_nan(x2, x1, **kwargs)\n",
    "\t\telif jnp.ndim(x1) == 1 and jnp.ndim(x2) == 1:\n",
    "\t\t\treturn self.compute_matrix(x1, x2, **kwargs)\n",
    "\t\telif jnp.ndim(x1) == 2 and jnp.ndim(x2) == 2:\n",
    "\t\t\treturn self.compute_batch(x1, x2, **kwargs)\n",
    "\t\telse:\n",
    "\t\t\treturn jnp.nan\n",
    "\n",
    "\t# Methods to use Kernel as a PyTree\n",
    "\tdef tree_flatten(self):\n",
    "\t\treturn tuple(self.__dict__.values()), None  # No static values\n",
    "\n",
    "\t@classmethod\n",
    "\tdef tree_unflatten(cls, _, children):\n",
    "\t\t# This class being abstract, this function fails when called on an \"abstract instance\",\n",
    "\t\t# as we don't know the number of parameters the constructor expects, yet we send it children.\n",
    "\t\t# On a subclass, this will work as expected as long as the constructor has a clear number of\n",
    "\t\t# kwargs as parameters.\n",
    "\t\treturn cls(*children, skip_check=True)\n",
    "\n",
    "\t@jit\n",
    "\tdef compute_scalar_if_not_nan(self, x1: jnp.ndarray, x2: jnp.ndarray, **kwargs) -> jnp.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tReturns NaN if either x1 or x2 is NaN, otherwise calls the compute_scalar method.\n",
    "\n",
    "\t\t:param x1: scalar array\n",
    "\t\t:param x2: scalar array\n",
    "\t\t:param kwargs: hyperparameters of the kernel\n",
    "\t\t:return: scalar array\n",
    "\t\t\"\"\"\n",
    "\t\treturn cond(jnp.isnan(x1) | jnp.isnan(x2), lambda _: jnp.nan,\n",
    "\t\t                lambda _: self.compute_scalar(x1, x2, **kwargs), None)\n",
    "\n",
    "\t@jit\n",
    "\tdef compute_scalar(self, x1: jnp.ndarray, x2: jnp.ndarray, **kwargs) -> jnp.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tCompute the kernel covariance value between two scalar arrays.\n",
    "\n",
    "\t\t:param x1: scalar array\n",
    "\t\t:param x2: scalar array\n",
    "\t\t:param kwargs: hyperparameters of the kernel\n",
    "\t\t:return: scalar array\n",
    "\t\t\"\"\"\n",
    "\t\treturn jnp.array(jnp.nan)  # To be overwritten in subclasses\n",
    "\n",
    "\t@jit\n",
    "\tdef compute_vector(self, x1: jnp.ndarray, x2: jnp.ndarray, **kwargs) -> jnp.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tCompute the kernel covariance value between a vector and a scalar.\n",
    "\n",
    "\t\t:param x1: vector array (N, )\n",
    "\t\t:param x2: scalar array\n",
    "\t\t:param kwargs: hyperparameters of the kernel\n",
    "\t\t:return: vector array (N, )\n",
    "\t\t\"\"\"\n",
    "\t\treturn vmap(lambda x: self.compute_scalar_if_not_nan(x, x2, **kwargs), in_axes=0)(x1)\n",
    "\n",
    "\t@jit\n",
    "\tdef compute_vector_if_not_nan(self, x1: jnp.ndarray, x2: jnp.ndarray, **kwargs) -> jnp.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tReturns an array of NaN if scalar is NaN, otherwise calls the compute_vector method.\n",
    "\n",
    "\t\t:param x1: vector array (N, )\n",
    "\t\t:param x2: scalar array\n",
    "\t\t:param kwargs: hyperparameters of the kernel\n",
    "\t\t:return: vector array (N, )\n",
    "\t\t\"\"\"\n",
    "\t\treturn cond(jnp.any(jnp.isnan(x2)), lambda _: x1 * jnp.nan, lambda _: self.compute_vector(x1, x2, **kwargs),\n",
    "\t\t                None)\n",
    "\n",
    "\t@jit\n",
    "\tdef compute_matrix(self, x1: jnp.ndarray, x2: jnp.ndarray, **kwargs) -> jnp.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tCompute the kernel covariance matrix between two vector arrays.\n",
    "\n",
    "\t\t:param x1: vector array (N, )\n",
    "\t\t:param x2: vector array (M, )\n",
    "\t\t:param kwargs: hyperparameters of the kernel\n",
    "\t\t:return: matrix array (N, M)\n",
    "\t\t\"\"\"\n",
    "\t\treturn vmap(lambda x: self.compute_vector_if_not_nan(x2, x, **kwargs), in_axes=0)(x1)\n",
    "\n",
    "\t@jit\n",
    "\tdef compute_batch(self, x1: jnp.ndarray, x2: jnp.ndarray, **kwargs) -> jnp.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tCompute the kernel covariance matrix between two batched vector arrays.\n",
    "\n",
    "\t\t:param x1: vector array (B, N)\n",
    "\t\t:param x2: vector array (B, M)\n",
    "\t\t:param kwargs: hyperparameters of the kernel. Each HP that is a scalar will be common to the whole batch, and\n",
    "\t\teach HP that is a vector will be distinct and thus must have shape (B, )\n",
    "\t\t:return: tensor array (B, N, M)\n",
    "\t\t\"\"\"\n",
    "\t\t# vmap(self.compute_matrix)(x1, x2, **kwargs)\n",
    "\t\tcommon_hps = {key: value for key, value in kwargs.items() if jnp.isscalar(value)}\n",
    "\t\tdistinct_hps = {key: value for key, value in kwargs.items() if not jnp.isscalar(value)}\n",
    "\n",
    "\t\treturn vmap(lambda x, y, hps: self.compute_matrix(x, y, **hps, **common_hps), in_axes=(0, 0, 0))(x1, x2,                                                                                           distinct_hps)"
   ],
   "id": "8f3b586721ed3c3c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.233287Z",
     "start_time": "2025-06-16T11:14:18.230715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@register_pytree_node_class\n",
    "class SEMagmaKernel(AbstractKernel):\n",
    "\tdef __init__(self, length_scale=None, variance=None, **kwargs):\n",
    "\t\tif length_scale is None:\n",
    "\t\t\tlength_scale = jnp.array([1.])\n",
    "\t\tif variance is None:\n",
    "\t\t\tvariance = jnp.array([1.])\n",
    "\t\tsuper().__init__(length_scale=length_scale, variance=variance, **kwargs)\n",
    "\n",
    "\t@jit\n",
    "\tdef compute_scalar(self, x1: jnp.ndarray, x2: jnp.ndarray, length_scale=None, variance=None) -> jnp.ndarray:\n",
    "\t\treturn jnp.exp(variance - jnp.exp(-length_scale) * jnp.sum((x1 - x2) ** 2) * 0.5)"
   ],
   "id": "2f45a9e6bf3ec1f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.246426Z",
     "start_time": "2025-06-16T11:14:18.243684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@register_pytree_node_class\n",
    "class NoisySEMagmaKernel(AbstractKernel):\n",
    "\tdef __init__(self, length_scale=None, variance=None, noise=None, **kwargs):\n",
    "\t\tif noise is None:\n",
    "\t\t\tnoise = jnp.array([-1.])\n",
    "\t\tsuper().__init__(length_scale=length_scale, variance=variance, noise=noise, **kwargs)\n",
    "\n",
    "\t@jit\n",
    "\tdef compute_scalar(self, x1: jnp.ndarray, x2: jnp.ndarray, length_scale=None, variance=None, noise=None) -> jnp.ndarray:\n",
    "\t\treturn cond(x1 == x2,\n",
    "\t\t            lambda _: jnp.exp(variance - jnp.exp(-length_scale) * jnp.sum((x1 - x2) ** 2) * 0.5) + jnp.exp(noise),\n",
    "\t\t            lambda _: jnp.exp(variance - jnp.exp(-length_scale) * jnp.sum((x1 - x2) ** 2) * 0.5)\n",
    "\t\t            , None)"
   ],
   "id": "431b1a9092b3b7eb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "ab63f428986d662f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperpost",
   "id": "dea4b0ed5104ad59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.264018Z",
     "start_time": "2025-06-16T11:14:18.262521Z"
    }
   },
   "cell_type": "code",
   "source": "# from MagmaClustPy.hyperpost import hyperpost",
   "id": "16d0e5a7ccee0124",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.325780Z",
     "start_time": "2025-06-16T11:14:18.277392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def hyperpost_common_input_common_hp(outputs, prior_mean, mean_cov_u, mean_cov_inv, task_cov, inputs_to_grid=None,\n",
    "                                     nugget=jnp.array(1e-10)):\n",
    "\teye = jnp.eye(task_cov.shape[-1])\n",
    "\n",
    "\t# Compute task covariance and its Cholesky factor\n",
    "\ttask_cov_u, _ = cho_factor(task_cov + eye * nugget)\n",
    "\ttask_cov_inv = cho_solve((task_cov_u, False), eye)\n",
    "\n",
    "\tif inputs_to_grid is not None:\n",
    "\t\ttask_cov_inv = jnp.zeros_like(mean_cov_inv).at[jnp.ix_(inputs_to_grid, inputs_to_grid)].set(task_cov_inv)\n",
    "\n",
    "\t# All tasks share same inputs and hyperparameters, so their inverse covariances are the same, and we can compute\n",
    "\t# one then multiply rather than compute all then sum\n",
    "\tpost_cov_inv, _ = cho_factor(mean_cov_inv + len(outputs) * task_cov_inv, )\n",
    "\tpost_cov = cho_solve((post_cov_inv, False), eye)\n",
    "\n",
    "\t# Compute posterior mean\n",
    "\tweighted_prior_mean = cho_solve((mean_cov_u, False), prior_mean)\n",
    "\tweighted_tasks = cho_solve((task_cov_u, False), outputs.sum(axis=0))\n",
    "\n",
    "\tif inputs_to_grid is not None:\n",
    "\t\tweighted_tasks = jnp.zeros_like(prior_mean).at[inputs_to_grid].set(weighted_tasks)\n",
    "\n",
    "\tpost_mean = cho_solve((post_cov_inv, False), weighted_prior_mean + weighted_tasks)\n",
    "\n",
    "\treturn post_mean, post_cov"
   ],
   "id": "4a8959973ec0f936",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.347474Z",
     "start_time": "2025-06-16T11:14:18.343805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def hyperpost_common_input_distinct_hp(outputs, prior_mean, mean_cov_u, mean_cov_inv, task_covs, inputs_to_grid=None,\n",
    "                                       nugget=jnp.array(1e-10)):\n",
    "\teye = jnp.broadcast_to(jnp.eye(task_covs.shape[-1]), task_covs.shape)\n",
    "\n",
    "\t# Compute task covariance and its Cholesky factor\n",
    "\t# task_covs_L = vmap(lambda x: cho_factor(x + eye * nugget, lower=True)[0])(task_covs)\n",
    "\ttask_covs_u, _ = cho_factor(task_covs + eye * nugget)\n",
    "\t# task_cov_inv = vmap(lambda L: cho_solve((L, True), eye))(task_covs_L).sum(axis=0)\n",
    "\ttask_cov_inv = cho_solve((task_covs_u, False), eye)\n",
    "\n",
    "\tif inputs_to_grid is not None:\n",
    "\t\ttask_cov_inv = jnp.zeros_like(mean_cov_inv).at[jnp.ix_(inputs_to_grid, inputs_to_grid)].set(task_cov_inv)\n",
    "\n",
    "\ttask_cov_inv = task_cov_inv.sum(axis=0)\n",
    "\n",
    "\tpost_cov_inv, _ = cho_factor(mean_cov_inv + task_cov_inv)\n",
    "\tpost_cov = cho_solve((post_cov_inv, False), eye[0])\n",
    "\n",
    "\t# Compute posterior mean\n",
    "\tweighted_prior_mean = cho_solve((mean_cov_u, False), prior_mean)\n",
    "\t# weighted_tasks = vmap(lambda L, o: cho_solve((L, True), o))(task_covs_L, outputs).sum(axis=0)\n",
    "\tweighted_tasks = cho_solve((task_covs_u, False), outputs).sum(axis=0)\n",
    "\n",
    "\tif inputs_to_grid is not None:\n",
    "\t\tweighted_tasks = jnp.zeros_like(prior_mean).at[inputs_to_grid].set(weighted_tasks)\n",
    "\n",
    "\tpost_mean = cho_solve((post_cov_inv, False), weighted_prior_mean + weighted_tasks)\n",
    "\n",
    "\treturn post_mean, post_cov"
   ],
   "id": "74ad499d9f82fc9f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.366457Z",
     "start_time": "2025-06-16T11:14:18.362738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def hyperpost_distinct_input(outputs, masks, prior_mean, mean_cov_u, mean_cov_inv, task_covs, inputs_to_grid=None,\n",
    "                             nugget=jnp.array(1e-10)):\n",
    "\t\"\"\"\n",
    "\tcomputes the hyperpost on distinct inputs\n",
    "\n",
    "\ttask_covs: (M, N, N), batch of unaligned covariances\n",
    "\t\"\"\"\n",
    "\tsmall_eye = jnp.broadcast_to(jnp.eye(task_covs.shape[-1]), task_covs.shape)\n",
    "\tbig_eye = jnp.eye(mean_cov_u.shape[-1])\n",
    "\n",
    "\t# task_covs is padded with NaNs. Replace them by their corresponding identity rows/cols\n",
    "\tmasks_2D = masks[:, :, None] & masks[:, None, :]\n",
    "\ttask_covs = jnp.where(masks_2D, task_covs, small_eye)\n",
    "\n",
    "\t# Posterior covariance\n",
    "\t# task_covs_L = vmap(lambda x: cho_factor(x + small_eye * nugget)[0])(task_covs)\n",
    "\ttask_covs_U, _ = cho_factor(task_covs + small_eye * nugget)\n",
    "\t# task_covs_inv = vmap(lambda L: cho_solve((L, False), small_eye))(task_covs_L)\n",
    "\ttask_covs_inv = cho_solve((task_covs_U, False), small_eye)\n",
    "\ttask_covs_inv -= jnp.where(masks_2D, 0, small_eye)  # Correction on the diagonal\n",
    "\ttask_cov_inv = task_covs_inv.sum(axis=0)\n",
    "\n",
    "\tif inputs_to_grid is not None:\n",
    "\t\ttask_cov_inv = jnp.zeros_like(mean_cov_inv).at[jnp.ix_(inputs_to_grid, inputs_to_grid)].set(task_cov_inv)\n",
    "\n",
    "\tpost_cov_inv, _ = cho_factor(mean_cov_inv + task_cov_inv)\n",
    "\tpost_cov = cho_solve((post_cov_inv, False), big_eye)\n",
    "\n",
    "\t# Posterior mean\n",
    "\tweighted_prior_mean = cho_solve((mean_cov_u, False), prior_mean)\n",
    "\toutputs = jnp.where(masks, outputs, 0)\n",
    "\t# weighted_tasks = vmap(lambda L, o: cho_solve((L, False), o))(task_covs_L, outputs).sum(axis=0)\n",
    "\tweighted_tasks = cho_solve((task_covs_U, False), outputs).sum(axis=0)\n",
    "\n",
    "\tif inputs_to_grid is not None:\n",
    "\t\tweighted_tasks = jnp.zeros_like(prior_mean).at[inputs_to_grid].set(weighted_tasks)\n",
    "\n",
    "\tpost_mean = cho_solve((post_cov_inv, False), weighted_prior_mean + weighted_tasks)\n",
    "\n",
    "\treturn post_mean, post_cov"
   ],
   "id": "5ac724b2749da21b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.382846Z",
     "start_time": "2025-06-16T11:14:18.379112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hyperpost(inputs, outputs, masks, prior_mean, mean_kernel, task_kernel, all_inputs=None, grid=None,\n",
    "              nugget=jnp.array(1e-10)):\n",
    "\t\"\"\"\n",
    "\tComputes the posterior mean and covariance of a Magma GP given the inputs, outputs, masks, prior mean and kernels.\n",
    "\n",
    "\t:param inputs: the preprocessed (padded and aligned) inputs\n",
    "\t:param outputs: the preprocessed outputs\n",
    "\t:param masks: the masks indicating which inputs are valid\n",
    "\t:param prior_mean: the prior mean, as a scalar or a vector of shape (N, ), where N is the length of the union of all\n",
    "\tinputs and the grid\n",
    "\t:param mean_kernel: kernel of the mean process, with hyperparameters loaded as attributes\n",
    "\t:param task_kernel: kernel of the task process, with hyperparameters loaded as attributes\n",
    "\t:param all_inputs: all distinct inputs. If not provided, it will be computed from the inputs\n",
    "\t:param grid: the grid on which the GP is defined. If not provided, the GP is defined on all distinct inputs\n",
    "\t:param nugget: nugget term to ensure numerical stability. Default is 1e-10\n",
    "\t:return: a 2-tuple of the posterior mean and covariance\n",
    "\t\"\"\"\n",
    "\tcommon_input = jnp.all(masks)\n",
    "\tcommon_hp = all([hp.ndim == 0 for hp in tree_flatten(task_kernel)[0]])\n",
    "\n",
    "\t# Merge inputs and grid to create all_inputs\n",
    "\tif all_inputs is None:\n",
    "\t\tif common_input:\n",
    "\t\t\tall_inputs = inputs[0]\n",
    "\t\telse:\n",
    "\t\t\tall_inputs = jnp.sort(jnp.unique(inputs.flatten()))\n",
    "\n",
    "\tif grid is None:\n",
    "\t\tgrid = all_inputs\n",
    "\t\tinputs_to_grid = None\n",
    "\telse:\n",
    "\t\tgrid = jnp.sort(jnp.unique(jnp.concatenate([all_inputs, grid])))\n",
    "\t\tinputs_to_grid = jnp.searchsorted(grid, all_inputs)\n",
    "\t\tcommon_input = False  # We need to pad the cov matrices to compute on the full grid\n",
    "\n",
    "\tif prior_mean.ndim == 0:\n",
    "\t\tprior_mean = jnp.broadcast_to(prior_mean, (len(grid),))\n",
    "\n",
    "\t# Numerical stability terms\n",
    "\teye = jnp.eye(grid.shape[0])\n",
    "\n",
    "\t# Compute mean covariance and its Cholesky factor\n",
    "\tmean_cov = mean_kernel(grid, grid)\n",
    "\tmean_cov_u, _ = cho_factor(mean_cov + eye * nugget)\n",
    "\tmean_cov_inv = cho_solve((mean_cov_u, False), eye)\n",
    "\n",
    "\tif common_input:\n",
    "\t\tif common_hp:\n",
    "\t\t\ttask_cov = task_kernel(grid)  # Shape: (N, N)\n",
    "\t\t\tres = hyperpost_common_input_common_hp(outputs, prior_mean, mean_cov_u, mean_cov_inv, task_cov, inputs_to_grid, nugget)\n",
    "\t\t\treturn res\n",
    "\n",
    "\t\telse:  # distinct HPs, we have to compute every task covariance but no padding is required\n",
    "\t\t\ttask_covs = task_kernel(inputs)  # Shape: (M, N, N)\n",
    "\t\t\tres = hyperpost_common_input_distinct_hp(outputs, prior_mean, mean_cov_u, mean_cov_inv, task_covs, inputs_to_grid, nugget)\n",
    "\t\t\treturn res\n",
    "\n",
    "\telse:  # No common input: we have to pad and mask\n",
    "\t\t# task_covs = task_kernel(jnp.broadcast_to(all_inputs, (len(inputs), len(all_inputs))))\n",
    "\t\ttask_covs = task_kernel(inputs)\n",
    "\t\tres = hyperpost_distinct_input(outputs, masks, prior_mean, mean_cov_u, mean_cov_inv, task_covs, inputs_to_grid, nugget)\n",
    "\t\treturn res"
   ],
   "id": "8280e0352986846c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "e9a2883b336b0215"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Likelihoods",
   "id": "4cd1c0a5b9b0a8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.404971Z",
     "start_time": "2025-06-16T11:14:18.400950Z"
    }
   },
   "cell_type": "code",
   "source": "from MagmaClustPy.likelihoods import magma_neg_likelihood",
   "id": "be433eeded4e337b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.421135Z",
     "start_time": "2025-06-16T11:14:18.419031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def solve_right_cholesky(A, B, nugget=jnp.array(1e-10)):\n",
    "\t\"\"\" Solves for X in X @ A = B \"\"\"\n",
    "\t# For X @ A = B, we can transpose both sides: A.T @ X.T = B.T\n",
    "\t# As A and B are symmetric, this simplifies to A @ X.T = B\n",
    "\t# Then solve for X.T and transpose the result\n",
    "\treturn cho_solve(cho_factor(A + nugget), B).T"
   ],
   "id": "eb7948a03aaaa79c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.442971Z",
     "start_time": "2025-06-16T11:14:18.439031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def magma_neg_likelihood_on_cov(covar, outputs, mean, mean_process_cov, mask=None, nugget=jnp.array(1e-10)):\n",
    "\tnugget_matrix = jnp.eye(outputs.shape[0]) * nugget\n",
    "\n",
    "\tif mask is not None:\n",
    "\t\t# Mask the covariance matrix and outputs\n",
    "\t\tmask_2D = mask[:, None] & mask[None, :]\n",
    "\t\tcovar = jnp.where(mask_2D, covar, jnp.eye(outputs.shape[0]))\n",
    "\t\toutputs = jnp.where(mask, outputs, 0)\n",
    "\t\tmean = jnp.where(mask, mean, 0)\n",
    "\t\tmean_process_cov = jnp.where(mask_2D, mean_process_cov, jnp.eye(outputs.shape[0]))\n",
    "\n",
    "\n",
    "\t# Compute log-likelihood\n",
    "\tmultiv_neg_log_lik = -logpdf(outputs, mean, covar + nugget_matrix)\n",
    "\n",
    "\t# Compute correction term\n",
    "\tcorrection = 0.5 * jnp.trace(solve_right_cholesky(covar, mean_process_cov, nugget=nugget))\n",
    "\n",
    "\tif mask is not None:\n",
    "\t\t# Correct log-likelihood for padding\n",
    "\t\t# The logpdf is computed as:\n",
    "\t\t# -0.5 * (N * log(2 * pi) + log(det(cov)) + (outputs - mean).T @ inv(cov) @ (outputs - mean))\n",
    "\t\t# det(cov) and the Mahalanobis distance are not affected by our padding\n",
    "\t\t# We only have to correct for the -0.5 * N * log(2 * pi) term, as N is bigger with padding\n",
    "\t\tnll_pad_correction = 0.5 * jnp.log(2 * jnp.pi) * jnp.sum(~mask, axis=0)\n",
    "\n",
    "\t\t# We also need to correct the correction term, as padding adds 1s to the diagonal and hence 1 to the trace\n",
    "\t\tcorr_pad_correction = 0.5 * jnp.sum(~mask, axis=0)\n",
    "\telse:\n",
    "\t\tnll_pad_correction = 0\n",
    "\t\tcorr_pad_correction = 0\n",
    "\n",
    "\tres = (multiv_neg_log_lik - nll_pad_correction) + (correction - corr_pad_correction)\n",
    "\treturn res"
   ],
   "id": "23809a116259edbb",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.462223Z",
     "start_time": "2025-06-16T11:14:18.459385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jit\n",
    "def magma_neg_likelihood(kernel, inputs, outputs: jnp.array, mean: jnp.array, mean_process_cov: jnp.array, mask=None,\n",
    "                         nugget=jnp.array(1e-10)):\n",
    "\t\"\"\"\n",
    "\tComputes the MAGMA log-likelihood.\n",
    "\n",
    "\t:param kernel: the kernel containing HPs to optimise. This kernel is used to compute the covariance (matrix `S`)\n",
    "\t:param inputs: inputs on which to compute the covariance matrix (shape (N, ))\n",
    "\t:param mask: boolean masks indicating which inputs and outputs to consider (shape (N, ))\n",
    "\t:param outputs: the observed values (shape (N, ))\n",
    "\t:param mean: the mean over the inputs (scalar or vector of shape (N, ))\n",
    "\t:param mean_process_cov: the hypper-posterior mean process covariance (matrix K^t)\n",
    "\t:param nugget: the nugget, for numerical stability\n",
    "\n",
    "\t:return: the negative log-likelihood (scalar)\n",
    "\t\"\"\"\n",
    "\tcovar = kernel(inputs)\n",
    "\n",
    "\t# check if we need to vmap\n",
    "\tif inputs.ndim == 1:\n",
    "\t\treturn magma_neg_likelihood_on_cov(covar, outputs, mean, mean_process_cov, mask, nugget)\n",
    "\telif inputs.ndim == 2:\n",
    "\t\treturn vmap(magma_neg_likelihood_on_cov, in_axes=(0, 0, None, None, 0, None))(covar, outputs, mean,\n",
    "\t\t                                                                              mean_process_cov, mask, nugget)\n",
    "\telse:\n",
    "\t\traise ValueError(\"inputs must be either 1D or 2D\")"
   ],
   "id": "610c031131bdb13a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "c9e911617605c8b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyper-parameters optimisation",
   "id": "e2dd5d7374824f75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.480098Z",
     "start_time": "2025-06-16T11:14:18.478213Z"
    }
   },
   "cell_type": "code",
   "source": "# from MagmaClustPy.hp_optimisation import optimise_hyperparameters",
   "id": "e93f064840df16b5",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.500667Z",
     "start_time": "2025-06-16T11:14:18.498353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class InfoState(NamedTuple):\n",
    "\titer_num: chex.Numeric\n",
    "\n",
    "\n",
    "def print_info():\n",
    "\tdef init_fn(params):\n",
    "\t\tdel params\n",
    "\t\treturn InfoState(iter_num=0)\n",
    "\n",
    "\tdef update_fn(updates, state, params, *, value, grad, **extra_args):\n",
    "\t\tdel params, extra_args\n",
    "\n",
    "\t\tjax.debug.print(\n",
    "\t\t\t'Iteration: {i}, Value: {v}, Gradient norm: {e}',\n",
    "\t\t\ti=state.iter_num,\n",
    "\t\t\tv=value,\n",
    "\t\t\te=otu.tree_l2_norm(grad),\n",
    "\t\t)\n",
    "\t\treturn updates, InfoState(iter_num=state.iter_num + 1)\n",
    "\n",
    "\treturn optax.GradientTransformationExtraArgs(init_fn, update_fn)"
   ],
   "id": "c4c688bf040feda2",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.519023Z",
     "start_time": "2025-06-16T11:14:18.516136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_opt(init_params, fun, opt, max_iter, tol):\n",
    "\tvalue_and_grad_fun = optax.value_and_grad_from_state(fun)\n",
    "\n",
    "\tdef step(carry):\n",
    "\t\tparams, state, prev_llh = carry\n",
    "\t\tvalue, grad = value_and_grad_fun(params, state=state)\n",
    "\t\tupdates, state = opt.update(grad, state, params, value=value, grad=grad, value_fn=fun)\n",
    "\t\tparams = optax.apply_updates(params, updates)\n",
    "\t\treturn params, state, value\n",
    "\n",
    "\tdef continuing_criterion(carry):\n",
    "\t\t# tol is not computed on the gradients but on the difference between current and previous likelihoods, to\n",
    "\t\t# prevent overfitting on ill-defined likelihood functions where variance can blow up.\n",
    "\t\t_, state, prev_llh = carry\n",
    "\t\titer_num = otu.tree_get(state, 'count')\n",
    "\t\tval = otu.tree_get(state, 'value')\n",
    "\t\tdiff = jnp.abs(val - prev_llh)\n",
    "\t\treturn (iter_num == 0) | ((iter_num < max_iter) & (diff >= tol))\n",
    "\n",
    "\tinit_carry = (init_params, opt.init(init_params),\n",
    "\t              jnp.array(jnp.inf))  # kernel params, initial state, first iter, previous likelihood\n",
    "\tfinal_params, final_state, final_llh = jax.lax.while_loop(\n",
    "\t\tcontinuing_criterion, step, init_carry\n",
    "\t)\n",
    "\treturn final_params, final_state, final_llh"
   ],
   "id": "805ffd078a6c6bfd",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.545772Z",
     "start_time": "2025-06-16T11:14:18.541980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def optimise_hyperparameters(mean_kernel, task_kernel, inputs, outputs, all_inputs, prior_mean, post_mean, post_cov,\n",
    "                             masks, nugget=jnp.array(1e-10), max_iter=100, tol=1e-3, verbose=False):\n",
    "\t# Optimise mean kernel\n",
    "\tif verbose:\n",
    "\t\tmean_opt = optax.chain(print_info(),\n",
    "                               optax.lbfgs(\n",
    "                                   #scale_init_precond=False,\n",
    "                                   linesearch=optax.scale_by_zoom_linesearch(\n",
    "                                       max_linesearch_steps=50,\n",
    "                                       verbose=True,\n",
    "                                       initial_guess_strategy='one'\n",
    "                                   )\n",
    "                               )\n",
    "                               )\n",
    "\telse:\n",
    "\t\tmean_opt = optax.lbfgs()\n",
    "\n",
    "\tdef mean_fun_wrapper(kern):\n",
    "\t\tres = magma_neg_likelihood(kern, all_inputs, post_mean, prior_mean, post_cov, mask=None, nugget=nugget)\n",
    "\t\treturn res\n",
    "\n",
    "\tnew_mean_kernel, _, mean_llh = run_opt(mean_kernel, mean_fun_wrapper, mean_opt, max_iter=max_iter, tol=tol)\n",
    "\n",
    "\t# Optimise task kernel\n",
    "\tif verbose:\n",
    "\t\ttask_opt = optax.chain(print_info(),\n",
    "                               optax.lbfgs(\n",
    "                                   #scale_init_precond=False,\n",
    "                                   linesearch=optax.scale_by_zoom_linesearch(\n",
    "                                       max_linesearch_steps=50,\n",
    "                                       verbose=True,\n",
    "                                       initial_guess_strategy='one'\n",
    "                                   )\n",
    "                               )\n",
    "                               )\n",
    "\telse:\n",
    "\t\ttask_opt = optax.lbfgs()\n",
    "\n",
    "\tdef task_fun_wrapper(kern):\n",
    "\t\tres = magma_neg_likelihood(kern, inputs, outputs, post_mean, post_cov, mask=masks, nugget=nugget).sum()\n",
    "\t\treturn res\n",
    "\n",
    "\tnew_task_kernel, _, task_llh = run_opt(task_kernel, task_fun_wrapper, task_opt, max_iter=max_iter, tol=tol)\n",
    "\n",
    "\treturn new_mean_kernel, new_task_kernel, mean_llh, task_llh"
   ],
   "id": "741394122280336f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "131b17a49f6a14d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run experiment",
   "id": "3287f2ccd00546c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Config",
   "id": "a378c493c540fa5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.568001Z",
     "start_time": "2025-06-16T11:14:18.565953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_ITER = 25\n",
    "CONVERG_THRESHOLD = 1e-10\n",
    "nugget = jnp.array(1e-2)"
   ],
   "id": "905141a8267ee767",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.640492Z",
     "start_time": "2025-06-16T11:14:18.585020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = \"small\"\n",
    "grids = {\n",
    "\t\"small\": jnp.arange(-10, 10, 0.5),\n",
    "\t\"medium\": jnp.arange(-100, 100, 0.5),\n",
    "\t\"large\": jnp.arange(-500, 500, 0.5),\n",
    "\t\"custom\": jnp.arange(-20, 20, 0.5)\n",
    "}\n",
    "grid = grids[dataset] if dataset in grids else grids[\"custom\"]\n",
    "common_input = False\n",
    "common_hp = True"
   ],
   "id": "fc4b15d05dbc405d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Start timer",
   "id": "a9f5f11bafdb69be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.650832Z",
     "start_time": "2025-06-16T11:14:18.649214Z"
    }
   },
   "cell_type": "code",
   "source": "start = time.time()",
   "id": "a977dc83979040a2",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data import",
   "id": "2e52dede973e84f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.670020Z",
     "start_time": "2025-06-16T11:14:18.665267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = pd.read_csv(f\"../dummy_datasets/{dataset}_{'common_input' if common_input else 'distinct_input'}_{'common_hp' if common_hp else 'distinct_hp'}.csv\")\n",
    "# db has 3 columns: ID, Input, Output"
   ],
   "id": "4029845efb88d613",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:18.688301Z",
     "start_time": "2025-06-16T11:14:18.685657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First 90% of IDs are for training, last 10% for testing\n",
    "train_ids = db[\"ID\"].unique()  # for debug\n",
    "test_ids = []  # for debug\n",
    "#train_ids = db[\"ID\"].unique()[:int(0.9 * db[\"ID\"].nunique())]\n",
    "#test_ids = db[\"ID\"].unique()[int(0.9 * db[\"ID\"].nunique()):]\n",
    "\n",
    "db_train = db[db[\"ID\"].isin(train_ids)]\n",
    "db_test = db[db[\"ID\"].isin(test_ids)]\n",
    "\n",
    "# N.b: data is already sort by ID and Input in the toy datasets, but in a real case scenario, we would need to sort it"
   ],
   "id": "f834da57adb83ea3",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data preprocessing",
   "id": "25c50cd3b2840c90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:21.255381Z",
     "start_time": "2025-06-16T11:14:18.714748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We need to convert the dataframe into jax arrays\n",
    "# inputs: (M, N) timestamps\n",
    "# outputs: (M, N) observed outputs\n",
    "# unique_inputs: (P,) unique timestamps (if common_input, P = N)\n",
    "all_inputs_train, padded_inputs_train, padded_outputs_train, masks_train = preprocess_db(db_train)\n",
    "all_inputs_train.shape, padded_outputs_train.shape"
   ],
   "id": "acdfa8d01a68148c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41,), (20, 41))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:21.276889Z",
     "start_time": "2025-06-16T11:14:21.272157Z"
    }
   },
   "cell_type": "code",
   "source": "np.asarray(padded_outputs_train)",
   "id": "92f0d296aebab7e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56.79648   ,         nan, 47.45987   , 47.982674  ,         nan,\n",
       "                nan, 53.703247  ,         nan,         nan,         nan,\n",
       "                nan, 39.313404  ,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan, 38.87174   , 39.344486  , 38.794037  ,         nan,\n",
       "                nan,         nan, 31.046186  , 30.664253  , 30.172342  ,\n",
       "                nan,         nan, 25.475653  , 20.951923  ,         nan,\n",
       "                nan,         nan,  8.368233  ,         nan,  5.0017056 ,\n",
       "                nan],\n",
       "       [        nan, 54.55903   , 51.62858   , 52.57326   , 54.477352  ,\n",
       "                nan, 57.90748   ,         nan, 53.40379   ,         nan,\n",
       "        40.963387  , 37.025715  ,         nan,         nan, 43.997414  ,\n",
       "        46.24601   , 47.21769   ,         nan, 42.003014  , 38.71247   ,\n",
       "        38.389164  , 39.26506   ,         nan,         nan, 39.83591   ,\n",
       "                nan, 32.578926  ,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan, 22.131807  ,         nan,\n",
       "                nan,  8.76073   ,  7.301952  ,         nan,         nan,\n",
       "                nan],\n",
       "       [        nan, 54.91108   , 53.106884  ,         nan, 53.581738  ,\n",
       "                nan, 55.773685  ,         nan, 49.343136  , 44.317726  ,\n",
       "                nan, 37.24733   , 37.422073  , 39.675922  , 43.438866  ,\n",
       "        44.739826  ,         nan,         nan, 42.29432   ,         nan,\n",
       "                nan, 37.301975  ,         nan,         nan,         nan,\n",
       "                nan, 30.996279  , 28.583677  ,         nan, 26.20372   ,\n",
       "                nan, 25.10208   ,         nan, 20.397728  ,         nan,\n",
       "                nan,         nan,  7.1236134 ,         nan,  3.6454823 ,\n",
       "                nan],\n",
       "       [        nan,         nan, 54.70948   , 52.7461    , 54.343258  ,\n",
       "        55.871227  , 56.74582   , 56.04277   ,         nan,         nan,\n",
       "        43.288788  , 39.810356  , 39.265835  ,         nan, 45.683804  ,\n",
       "        47.848488  , 51.698826  ,         nan, 47.239857  ,         nan,\n",
       "                nan,         nan,         nan,         nan, 39.89745   ,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "        30.548067  ,         nan,         nan, 20.885426  , 16.342857  ,\n",
       "                nan, 10.118774  ,         nan,         nan,  4.3872027 ,\n",
       "         2.0069425 ],\n",
       "       [57.874546  ,         nan, 54.38915   , 54.888783  , 58.603287  ,\n",
       "                nan, 60.79674   ,         nan,         nan, 49.350384  ,\n",
       "        42.579372  ,         nan, 38.270927  ,         nan,         nan,\n",
       "                nan, 44.939835  , 43.866898  ,         nan, 38.82004   ,\n",
       "        37.737167  ,         nan,         nan, 37.56506   , 37.946198  ,\n",
       "                nan,         nan,         nan,         nan, 33.155666  ,\n",
       "                nan, 31.70431   ,         nan, 23.631443  ,         nan,\n",
       "        12.428239  ,  9.261386  ,  8.271081  ,         nan,         nan,\n",
       "                nan],\n",
       "       [        nan, 51.639782  ,         nan, 47.947567  , 51.23566   ,\n",
       "        54.337208  ,         nan,         nan,         nan,         nan,\n",
       "                nan, 39.52018   ,         nan, 38.437794  , 41.093613  ,\n",
       "                nan,         nan, 48.77484   ,         nan, 45.37877   ,\n",
       "                nan, 42.109524  ,         nan, 41.571754  , 41.133125  ,\n",
       "                nan,         nan, 32.3315    ,         nan, 30.913288  ,\n",
       "                nan, 30.007261  ,         nan, 22.197533  , 16.331268  ,\n",
       "                nan,         nan,  6.4323373 ,  4.2661686 ,         nan,\n",
       "         0.5500716 ],\n",
       "       [        nan, 51.884914  , 49.929485  , 49.90833   , 51.721916  ,\n",
       "        53.234867  , 54.029648  ,         nan,         nan, 47.104214  ,\n",
       "                nan, 40.565155  , 39.21188   , 40.45413   , 42.319366  ,\n",
       "                nan,         nan,         nan,         nan, 44.009815  ,\n",
       "        42.095406  ,         nan, 40.32033   , 41.33058   , 41.50151   ,\n",
       "                nan,         nan,         nan, 31.903965  , 33.098747  ,\n",
       "                nan, 34.537575  ,         nan,         nan, 19.636736  ,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan],\n",
       "       [        nan, 54.867973  ,         nan, 54.051453  ,         nan,\n",
       "                nan, 59.74901   , 57.55981   , 52.876804  ,         nan,\n",
       "                nan,         nan,         nan, 41.15374   ,         nan,\n",
       "        47.971672  ,         nan,         nan, 47.04867   , 43.81234   ,\n",
       "                nan,         nan, 39.39606   , 39.770943  , 37.501842  ,\n",
       "        34.64279   , 31.858042  , 29.494009  ,         nan, 30.828415  ,\n",
       "                nan, 29.405212  ,         nan,         nan,         nan,\n",
       "                nan,         nan,  5.3316083 ,         nan,  1.6139889 ,\n",
       "        -0.4157781 ],\n",
       "       [        nan,         nan, 52.09055   ,         nan, 52.292835  ,\n",
       "                nan,         nan,         nan, 54.592434  ,         nan,\n",
       "                nan,         nan, 37.10199   , 37.94433   ,         nan,\n",
       "                nan, 47.06782   ,         nan,         nan, 40.614124  ,\n",
       "        37.72713   ,         nan,         nan, 40.220078  , 38.277256  ,\n",
       "                nan, 32.46125   , 29.380829  , 29.142965  , 31.356964  ,\n",
       "        30.460371  , 30.878359  , 28.386976  ,         nan, 16.962025  ,\n",
       "                nan,         nan,  8.663397  ,  8.399487  ,         nan,\n",
       "                nan],\n",
       "       [57.379692  ,         nan,         nan,         nan, 52.948986  ,\n",
       "                nan, 54.530716  ,         nan, 48.747097  , 43.55216   ,\n",
       "        38.06498   ,         nan,         nan, 38.313988  , 41.80215   ,\n",
       "                nan, 48.35563   ,         nan,         nan,         nan,\n",
       "                nan, 37.879333  , 37.572517  ,         nan, 39.828316  ,\n",
       "        36.637913  , 32.957947  ,         nan,         nan, 31.274343  ,\n",
       "                nan, 31.208326  ,         nan,         nan,         nan,\n",
       "                nan,  6.468759  ,  4.9630017 ,  4.047182  ,  1.041341  ,\n",
       "                nan],\n",
       "       [        nan, 55.944508  ,         nan, 54.04332   ,         nan,\n",
       "                nan, 59.349804  ,         nan, 53.978325  ,         nan,\n",
       "                nan,         nan, 39.83965   , 41.646984  ,         nan,\n",
       "        49.227493  ,         nan,         nan, 46.928986  , 41.931652  ,\n",
       "                nan, 39.05065   ,         nan, 41.328278  , 41.00299   ,\n",
       "                nan, 32.500244  ,         nan,         nan, 29.910038  ,\n",
       "                nan, 29.675058  ,         nan, 22.056143  , 17.707472  ,\n",
       "        12.962907  , 10.373144  ,         nan,         nan,         nan,\n",
       "         1.5845664 ],\n",
       "       [61.736343  , 58.538338  ,         nan, 54.567905  ,         nan,\n",
       "                nan,         nan, 55.224987  ,         nan, 48.119583  ,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan, 50.45984   , 50.300762  ,         nan, 46.66474   ,\n",
       "                nan,         nan, 43.505413  , 42.302116  ,         nan,\n",
       "                nan, 33.751465  , 30.372452  ,         nan, 31.140089  ,\n",
       "        31.108528  , 30.18208   ,         nan,         nan,         nan,\n",
       "        11.576363  , 10.415044  ,  9.617328  ,  8.78068   ,         nan,\n",
       "         1.8257294 ],\n",
       "       [        nan,         nan,         nan,         nan, 53.795616  ,\n",
       "                nan, 58.71785   ,         nan, 55.422226  ,         nan,\n",
       "                nan, 37.156376  ,         nan, 33.950813  ,         nan,\n",
       "                nan,         nan,         nan,         nan, 40.699566  ,\n",
       "                nan, 37.68288   ,         nan, 38.995342  ,         nan,\n",
       "                nan, 33.713596  , 31.615433  , 29.303646  ,         nan,\n",
       "        29.913982  , 28.165258  ,         nan, 19.049053  , 13.656748  ,\n",
       "                nan,  6.421815  ,  5.3259478 ,  4.0466056 ,  0.09449904,\n",
       "        -2.4316845 ],\n",
       "       [        nan,         nan, 50.21467   , 50.352345  , 52.98697   ,\n",
       "                nan,         nan,         nan, 57.095303  ,         nan,\n",
       "                nan, 43.735817  , 41.521366  ,         nan, 41.328815  ,\n",
       "        43.423794  ,         nan, 45.420216  ,         nan, 41.23149   ,\n",
       "                nan,         nan, 38.41103   , 38.97994   ,         nan,\n",
       "        37.04702   , 33.87508   , 30.775831  ,         nan,         nan,\n",
       "        30.377113  ,         nan,         nan,         nan,         nan,\n",
       "         9.897804  ,         nan,  7.010897  ,  5.4024096 ,  3.613215  ,\n",
       "                nan],\n",
       "       [        nan,         nan, 51.279537  , 50.354176  , 51.56817   ,\n",
       "                nan, 56.682472  , 55.715145  ,         nan, 49.222088  ,\n",
       "        44.14192   ,         nan, 38.81856   ,         nan,         nan,\n",
       "        42.576275  , 45.09801   ,         nan,         nan, 43.58544   ,\n",
       "                nan,         nan,         nan,         nan, 39.29066   ,\n",
       "                nan,         nan,         nan, 29.426224  , 28.916016  ,\n",
       "        29.264673  , 26.808985  ,         nan,         nan, 11.773349  ,\n",
       "                nan,  6.5237484 ,  7.141787  ,  7.1035085 ,         nan,\n",
       "                nan],\n",
       "       [        nan,         nan,         nan, 50.492863  , 52.786263  ,\n",
       "        54.51772   , 56.684116  , 55.295303  ,         nan,         nan,\n",
       "                nan,         nan,         nan, 38.577526  ,         nan,\n",
       "                nan, 46.11829   , 46.64914   ,         nan,         nan,\n",
       "        40.017044  ,         nan, 38.343544  , 37.457947  , 36.186234  ,\n",
       "        34.98992   ,         nan, 29.644264  ,         nan, 31.133139  ,\n",
       "        32.842854  ,         nan,         nan,         nan,         nan,\n",
       "        12.205872  ,  7.605518  ,  6.8459225 ,         nan,         nan,\n",
       "         0.15132757],\n",
       "       [59.75348   ,         nan,         nan, 50.253033  , 51.602783  ,\n",
       "        55.54705   , 57.904682  ,         nan,         nan,         nan,\n",
       "        42.61102   ,         nan,         nan, 39.462257  ,         nan,\n",
       "                nan, 49.444126  ,         nan, 46.527588  ,         nan,\n",
       "        37.58056   , 34.58782   ,         nan, 35.83299   , 36.301674  ,\n",
       "        35.24505   , 32.865852  , 30.78428   ,         nan, 31.374607  ,\n",
       "                nan, 31.76581   , 29.567745  ,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "        -1.3909534 ],\n",
       "       [57.03893   , 52.85613   , 49.830315  , 50.129948  , 53.18718   ,\n",
       "                nan, 57.74221   ,         nan, 55.691246  , 51.399036  ,\n",
       "                nan,         nan,         nan,         nan, 39.645863  ,\n",
       "                nan,         nan,         nan, 40.441612  ,         nan,\n",
       "        35.214634  , 37.061817  ,         nan,         nan,         nan,\n",
       "        35.556282  ,         nan, 32.60006   ,         nan,         nan,\n",
       "        34.50145   , 34.928932  , 29.849394  ,         nan, 15.264763  ,\n",
       "         8.815924  ,  6.5024967 ,         nan,         nan,         nan,\n",
       "                nan],\n",
       "       [        nan, 51.748367  , 49.5466    ,         nan, 51.682484  ,\n",
       "                nan, 53.599796  , 52.34492   , 48.197445  ,         nan,\n",
       "        38.677177  ,         nan, 35.732037  ,         nan,         nan,\n",
       "                nan, 48.407227  ,         nan, 45.726913  ,         nan,\n",
       "                nan,         nan,         nan, 41.033524  ,         nan,\n",
       "        39.096863  ,         nan, 35.24459   , 34.38151   , 33.816845  ,\n",
       "                nan, 31.216179  ,         nan, 20.593592  , 13.680324  ,\n",
       "                nan,         nan,  4.3265076 ,         nan,  2.2378259 ,\n",
       "                nan],\n",
       "       [        nan,         nan, 53.25322   , 51.99131   , 53.232723  ,\n",
       "                nan,         nan, 55.963955  , 52.77777   ,         nan,\n",
       "                nan, 37.89898   ,         nan,         nan, 45.200096  ,\n",
       "                nan,         nan, 46.49053   ,         nan,         nan,\n",
       "        42.573086  , 42.354233  ,         nan,         nan, 41.413017  ,\n",
       "        38.02378   ,         nan, 32.512444  , 31.134098  ,         nan,\n",
       "                nan,         nan, 27.396309  , 23.165483  , 16.02542   ,\n",
       "                nan,  4.3149734 ,         nan,         nan, -2.1005647 ,\n",
       "        -3.568277  ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:21.324176Z",
     "start_time": "2025-06-16T11:14:21.321276Z"
    }
   },
   "cell_type": "code",
   "source": "np.asarray(masks_train)",
   "id": "8f7f6b11724041a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True,  True, False, False,  True, False, False,\n",
       "        False, False,  True, False, False, False, False, False, False,\n",
       "        False, False, False,  True,  True,  True, False, False, False,\n",
       "         True,  True,  True, False, False,  True,  True, False, False,\n",
       "        False,  True, False,  True, False],\n",
       "       [False,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        False,  True,  True, False, False,  True,  True,  True, False,\n",
       "         True,  True,  True,  True, False, False,  True, False,  True,\n",
       "        False, False, False, False, False, False,  True, False, False,\n",
       "         True,  True, False, False, False],\n",
       "       [False,  True,  True, False,  True, False,  True, False,  True,\n",
       "         True, False,  True,  True,  True,  True,  True, False, False,\n",
       "         True, False, False,  True, False, False, False, False,  True,\n",
       "         True, False,  True, False,  True, False,  True, False, False,\n",
       "        False,  True, False,  True, False],\n",
       "       [False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        False,  True,  True,  True, False,  True,  True,  True, False,\n",
       "         True, False, False, False, False, False,  True, False, False,\n",
       "        False, False, False,  True, False, False,  True,  True, False,\n",
       "         True, False, False,  True,  True],\n",
       "       [ True, False,  True,  True,  True, False,  True, False, False,\n",
       "         True,  True, False,  True, False, False, False,  True,  True,\n",
       "        False,  True,  True, False, False,  True,  True, False, False,\n",
       "        False, False,  True, False,  True, False,  True, False,  True,\n",
       "         True,  True, False, False, False],\n",
       "       [False,  True, False,  True,  True,  True, False, False, False,\n",
       "        False, False,  True, False,  True,  True, False, False,  True,\n",
       "        False,  True, False,  True, False,  True,  True, False, False,\n",
       "         True, False,  True, False,  True, False,  True,  True, False,\n",
       "        False,  True,  True, False,  True],\n",
       "       [False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "         True, False,  True,  True,  True,  True, False, False, False,\n",
       "        False,  True,  True, False,  True,  True,  True, False, False,\n",
       "        False,  True,  True, False,  True, False, False,  True, False,\n",
       "        False, False, False, False, False],\n",
       "       [False,  True, False,  True, False, False,  True,  True,  True,\n",
       "        False, False, False, False,  True, False,  True, False, False,\n",
       "         True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "         True, False,  True, False,  True, False, False, False, False,\n",
       "        False,  True, False,  True,  True],\n",
       "       [False, False,  True, False,  True, False, False, False,  True,\n",
       "        False, False, False,  True,  True, False, False,  True, False,\n",
       "        False,  True,  True, False, False,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        False,  True,  True, False, False],\n",
       "       [ True, False, False, False,  True, False,  True, False,  True,\n",
       "         True,  True, False, False,  True,  True, False,  True, False,\n",
       "        False, False, False,  True,  True, False,  True,  True,  True,\n",
       "        False, False,  True, False,  True, False, False, False, False,\n",
       "         True,  True,  True,  True, False],\n",
       "       [False,  True, False,  True, False, False,  True, False,  True,\n",
       "        False, False, False,  True,  True, False,  True, False, False,\n",
       "         True,  True, False,  True, False,  True,  True, False,  True,\n",
       "        False, False,  True, False,  True, False,  True,  True,  True,\n",
       "         True, False, False, False,  True],\n",
       "       [ True,  True, False,  True, False, False, False,  True, False,\n",
       "         True, False, False, False, False, False, False,  True,  True,\n",
       "        False,  True, False, False,  True,  True, False, False,  True,\n",
       "         True, False,  True,  True,  True, False, False, False,  True,\n",
       "         True,  True,  True, False,  True],\n",
       "       [False, False, False, False,  True, False,  True, False,  True,\n",
       "        False, False,  True, False,  True, False, False, False, False,\n",
       "        False,  True, False,  True, False,  True, False, False,  True,\n",
       "         True,  True, False,  True,  True, False,  True,  True, False,\n",
       "         True,  True,  True,  True,  True],\n",
       "       [False, False,  True,  True,  True, False, False, False,  True,\n",
       "        False, False,  True,  True, False,  True,  True, False,  True,\n",
       "        False,  True, False, False,  True,  True, False,  True,  True,\n",
       "         True, False, False,  True, False, False, False, False,  True,\n",
       "        False,  True,  True,  True, False],\n",
       "       [False, False,  True,  True,  True, False,  True,  True, False,\n",
       "         True,  True, False,  True, False, False,  True,  True, False,\n",
       "        False,  True, False, False, False, False,  True, False, False,\n",
       "        False,  True,  True,  True,  True, False, False,  True, False,\n",
       "         True,  True,  True, False, False],\n",
       "       [False, False, False,  True,  True,  True,  True,  True, False,\n",
       "        False, False, False, False,  True, False, False,  True,  True,\n",
       "        False, False,  True, False,  True,  True,  True,  True, False,\n",
       "         True, False,  True,  True, False, False, False, False,  True,\n",
       "         True,  True, False, False,  True],\n",
       "       [ True, False, False,  True,  True,  True,  True, False, False,\n",
       "        False,  True, False, False,  True, False, False,  True, False,\n",
       "         True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "         True, False,  True, False,  True,  True, False, False, False,\n",
       "        False, False, False, False,  True],\n",
       "       [ True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "         True, False, False, False, False,  True, False, False, False,\n",
       "         True, False,  True,  True, False, False, False,  True, False,\n",
       "         True, False, False,  True,  True,  True, False,  True,  True,\n",
       "         True, False, False, False, False],\n",
       "       [False,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        False,  True, False,  True, False, False, False,  True, False,\n",
       "         True, False, False, False, False,  True, False,  True, False,\n",
       "         True,  True,  True, False,  True, False,  True,  True, False,\n",
       "        False,  True, False,  True, False],\n",
       "       [False, False,  True,  True,  True, False, False,  True,  True,\n",
       "        False, False,  True, False, False,  True, False, False,  True,\n",
       "        False, False,  True,  True, False, False,  True,  True, False,\n",
       "         True,  True, False, False, False,  True,  True,  True, False,\n",
       "         True, False, False,  True,  True]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "dc737367d4fe304a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:21.463634Z",
     "start_time": "2025-06-16T11:14:21.442641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Priors\n",
    "prior_mean = jnp.zeros_like(all_inputs_train)\n",
    "mean_kernel = SEMagmaKernel(length_scale=0.9, variance=1.5)\n",
    "\n",
    "if common_hp:\n",
    "\ttask_kernel = NoisySEMagmaKernel(length_scale=0.3, variance=1., noise=-2.5)\n",
    "else:\n",
    "\ttask_kernel = NoisySEMagmaKernel(length_scale=jnp.array([0.3] * padded_inputs_train.shape[0]), variance=jnp.array([1.] * padded_inputs_train.shape[0]), noise=jnp.array([-2.5] * padded_inputs_train.shape[0]))"
   ],
   "id": "1c9ccf5234311280",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:43:24.374840Z",
     "start_time": "2025-06-16T11:14:32.782320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prev_mean_llh = jnp.inf\n",
    "prev_task_llh = jnp.inf\n",
    "conv_ratio = jnp.inf\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "\tprint(f\"Iteration {i:4}\\tLlhs: {prev_mean_llh:12.4f}, {prev_task_llh:12.4f}\\tConv. Ratio: {conv_ratio:.5f}\\t\\n\\tMean: {mean_kernel}\\t\\n\\tTask: {task_kernel}\")\n",
    "\t# e-step: compute hyper-posterior\n",
    "\tpost_mean, post_cov = hyperpost(padded_inputs_train, padded_outputs_train, masks_train, prior_mean, mean_kernel, task_kernel, all_inputs=all_inputs_train, nugget=nugget)\n",
    "\n",
    "\t# m-step: update hyperparameters\n",
    "\tmean_kernel, task_kernel, mean_llh, task_llh = optimise_hyperparameters(mean_kernel, task_kernel, padded_inputs_train, padded_outputs_train, all_inputs_train, prior_mean, post_mean, post_cov, masks_train, nugget=nugget, verbose=True)\n",
    "\n",
    "\t# Check convergence\n",
    "\tif i > 0:\n",
    "\t\tconv_ratio = jnp.abs((prev_mean_llh + prev_task_llh) - (mean_llh + task_llh)) / jnp.abs(prev_mean_llh + prev_task_llh)\n",
    "\t\tif conv_ratio < CONVERG_THRESHOLD:\n",
    "\t\t\tprint(f\"Convergence reached after {i+1} iterations.\\tLlhs: {mean_llh:12.4f}, {task_llh:12.4f}\\n\\tMean: {mean_kernel}\\n\\tTask: {task_kernel}\")\n",
    "\t\t\tbreak\n",
    "\n",
    "\tif i == MAX_ITER - 1:\n",
    "\t\tprint(f\"WARNING: Maximum number of iterations reached.\\nLast modif: {jnp.abs(prev_mean_llh - mean_llh).item()} & {jnp.abs(prev_task_llh - task_llh).item()}\")\n",
    "\n",
    "\tprev_mean_llh = mean_llh\n",
    "\tprev_task_llh = task_llh"
   ],
   "id": "50b9f3d8c807f51b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0\tLlhs:          inf,          inf\tConv. Ratio: inf\t\n",
      "\tMean: SEMagmaKernel(length_scale=0.8999999761581421, variance=1.5)\t\n",
      "\tTask: NoisySEMagmaKernel(length_scale=0.30000001192092896, variance=1.0, noise=-2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while evaluating expression: not jnp.isfinite(res[0]) or not jnp.isfinite(res[1])\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/simonlejoly/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/_pydevd_bundle/pydevd_utils.py\", line 670, in eval_expression\n",
      "    return eval(expression, globals, locals)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/array.py\", line 305, in __bool__\n",
      "    core.check_bool_conversion(self)\n",
      "  File \"/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/core.py\", line 724, in check_bool_conversion\n",
      "    raise ValueError(\"The truth value of an array with more than one element\"\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m post_mean, post_cov \u001B[38;5;241m=\u001B[39m hyperpost(padded_inputs_train, padded_outputs_train, masks_train, prior_mean, mean_kernel, task_kernel, all_inputs\u001B[38;5;241m=\u001B[39mall_inputs_train, nugget\u001B[38;5;241m=\u001B[39mnugget)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# m-step: update hyperparameters\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m mean_kernel, task_kernel, mean_llh, task_llh \u001B[38;5;241m=\u001B[39m optimise_hyperparameters(mean_kernel, task_kernel, padded_inputs_train, padded_outputs_train, all_inputs_train, prior_mean, post_mean, post_cov, masks_train, nugget\u001B[38;5;241m=\u001B[39mnugget, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Check convergence\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[0;32mIn[21], line 22\u001B[0m, in \u001B[0;36moptimise_hyperparameters\u001B[0;34m(mean_kernel, task_kernel, inputs, outputs, all_inputs, prior_mean, post_mean, post_cov, masks, nugget, max_iter, tol, verbose)\u001B[0m\n\u001B[1;32m     19\u001B[0m \tres \u001B[38;5;241m=\u001B[39m magma_neg_likelihood(kern, all_inputs, post_mean, prior_mean, post_cov, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, nugget\u001B[38;5;241m=\u001B[39mnugget)\n\u001B[1;32m     20\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m res\n\u001B[0;32m---> 22\u001B[0m new_mean_kernel, _, mean_llh \u001B[38;5;241m=\u001B[39m run_opt(mean_kernel, mean_fun_wrapper, mean_opt, max_iter\u001B[38;5;241m=\u001B[39mmax_iter, tol\u001B[38;5;241m=\u001B[39mtol)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Optimise task kernel\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "Cell \u001B[0;32mIn[20], line 22\u001B[0m, in \u001B[0;36mrun_opt\u001B[0;34m(init_params, fun, opt, max_iter, tol)\u001B[0m\n\u001B[1;32m     18\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m (iter_num \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m|\u001B[39m ((iter_num \u001B[38;5;241m<\u001B[39m max_iter) \u001B[38;5;241m&\u001B[39m (diff \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m tol))\n\u001B[1;32m     20\u001B[0m init_carry \u001B[38;5;241m=\u001B[39m (init_params, opt\u001B[38;5;241m.\u001B[39minit(init_params),\n\u001B[1;32m     21\u001B[0m               jnp\u001B[38;5;241m.\u001B[39marray(jnp\u001B[38;5;241m.\u001B[39minf))  \u001B[38;5;66;03m# kernel params, initial state, first iter, previous likelihood\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m final_params, final_state, final_llh \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mlax\u001B[38;5;241m.\u001B[39mwhile_loop(\n\u001B[1;32m     23\u001B[0m \tcontinuing_criterion, step, init_carry\n\u001B[1;32m     24\u001B[0m )\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m final_params, final_state, final_llh\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/lax/control_flow/loops.py:1369\u001B[0m, in \u001B[0;36mwhile_loop\u001B[0;34m(cond_fun, body_fun, init_val)\u001B[0m\n\u001B[1;32m   1367\u001B[0m   val \u001B[38;5;241m=\u001B[39m tree_map(lax\u001B[38;5;241m.\u001B[39masarray, init_val)\n\u001B[1;32m   1368\u001B[0m   \u001B[38;5;28;01mwhile\u001B[39;00m cond_fun(val):\n\u001B[0;32m-> 1369\u001B[0m     val \u001B[38;5;241m=\u001B[39m tree_map(lax\u001B[38;5;241m.\u001B[39masarray, body_fun(val))\n\u001B[1;32m   1370\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m val\n\u001B[1;32m   1371\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39mConcretizationTypeError:\n\u001B[1;32m   1372\u001B[0m   \u001B[38;5;66;03m# Can't run this while_loop in Python (e.g. because there's a vmap\u001B[39;00m\n\u001B[1;32m   1373\u001B[0m   \u001B[38;5;66;03m# transformation on it), so we fall back to the primitive version.\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[20], line 6\u001B[0m, in \u001B[0;36mrun_opt.<locals>.step\u001B[0;34m(carry)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(carry):\n\u001B[1;32m      5\u001B[0m \tparams, state, prev_llh \u001B[38;5;241m=\u001B[39m carry\n\u001B[0;32m----> 6\u001B[0m \tvalue, grad \u001B[38;5;241m=\u001B[39m value_and_grad_fun(params, state\u001B[38;5;241m=\u001B[39mstate)\n\u001B[1;32m      7\u001B[0m \tupdates, state \u001B[38;5;241m=\u001B[39m opt\u001B[38;5;241m.\u001B[39mupdate(grad, state, params, value\u001B[38;5;241m=\u001B[39mvalue, grad\u001B[38;5;241m=\u001B[39mgrad, value_fn\u001B[38;5;241m=\u001B[39mfun)\n\u001B[1;32m      8\u001B[0m \tparams \u001B[38;5;241m=\u001B[39m optax\u001B[38;5;241m.\u001B[39mapply_updates(params, updates)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/optax/_src/utils.py:299\u001B[0m, in \u001B[0;36mvalue_and_grad_from_state.<locals>._value_and_grad\u001B[0;34m(params, state, *fn_args, **fn_kwargs)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m (grad \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    294\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    295\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValue or gradient not found in the state. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    296\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMake sure that these values are stored in the state by the \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    297\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    298\u001B[0m   )\n\u001B[0;32m--> 299\u001B[0m value, grad \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mlax\u001B[38;5;241m.\u001B[39mcond(\n\u001B[1;32m    300\u001B[0m     (\u001B[38;5;241m~\u001B[39mjnp\u001B[38;5;241m.\u001B[39misinf(value)) \u001B[38;5;241m&\u001B[39m (\u001B[38;5;241m~\u001B[39mjnp\u001B[38;5;241m.\u001B[39misnan(value)),\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m \u001B[38;5;241m*\u001B[39m_: (value, grad),\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m p, a, kwa: jax\u001B[38;5;241m.\u001B[39mvalue_and_grad(value_fn)(p, \u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwa),\n\u001B[1;32m    303\u001B[0m     params,\n\u001B[1;32m    304\u001B[0m     fn_args,\n\u001B[1;32m    305\u001B[0m     fn_kwargs,\n\u001B[1;32m    306\u001B[0m )\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m value, grad\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/lax/control_flow/conditionals.py:309\u001B[0m, in \u001B[0;36mcond\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    306\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(true_fun) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(false_fun):\n\u001B[1;32m    307\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _cond_with_per_branch_args(\u001B[38;5;241m*\u001B[39mba\u001B[38;5;241m.\u001B[39margs)\n\u001B[0;32m--> 309\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _cond(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/lax/control_flow/conditionals.py:237\u001B[0m, in \u001B[0;36m_cond\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m true_fun(\u001B[38;5;241m*\u001B[39moperands)\n\u001B[1;32m    236\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 237\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m false_fun(\u001B[38;5;241m*\u001B[39moperands)\n\u001B[1;32m    239\u001B[0m ops, ops_tree \u001B[38;5;241m=\u001B[39m tree_flatten(operands)\n\u001B[1;32m    240\u001B[0m ops_avals \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mmap\u001B[39m(core\u001B[38;5;241m.\u001B[39mget_aval, ops))\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/optax/_src/utils.py:302\u001B[0m, in \u001B[0;36mvalue_and_grad_from_state.<locals>._value_and_grad.<locals>.<lambda>\u001B[0;34m(p, a, kwa)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m (grad \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    294\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    295\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValue or gradient not found in the state. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    296\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMake sure that these values are stored in the state by the \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    297\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    298\u001B[0m   )\n\u001B[1;32m    299\u001B[0m value, grad \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mlax\u001B[38;5;241m.\u001B[39mcond(\n\u001B[1;32m    300\u001B[0m     (\u001B[38;5;241m~\u001B[39mjnp\u001B[38;5;241m.\u001B[39misinf(value)) \u001B[38;5;241m&\u001B[39m (\u001B[38;5;241m~\u001B[39mjnp\u001B[38;5;241m.\u001B[39misnan(value)),\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m \u001B[38;5;241m*\u001B[39m_: (value, grad),\n\u001B[0;32m--> 302\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m p, a, kwa: jax\u001B[38;5;241m.\u001B[39mvalue_and_grad(value_fn)(p, \u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwa),\n\u001B[1;32m    303\u001B[0m     params,\n\u001B[1;32m    304\u001B[0m     fn_args,\n\u001B[1;32m    305\u001B[0m     fn_kwargs,\n\u001B[1;32m    306\u001B[0m )\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m value, grad\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/api.py:472\u001B[0m, in \u001B[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    470\u001B[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001B[1;32m    471\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_aux:\n\u001B[0;32m--> 472\u001B[0m   ans, vjp_py \u001B[38;5;241m=\u001B[39m _vjp(f_partial, \u001B[38;5;241m*\u001B[39mdyn_args)\n\u001B[1;32m    473\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    474\u001B[0m   ans, vjp_py, aux \u001B[38;5;241m=\u001B[39m _vjp(\n\u001B[1;32m    475\u001B[0m       f_partial, \u001B[38;5;241m*\u001B[39mdyn_args, has_aux\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/api.py:2020\u001B[0m, in \u001B[0;36m_vjp\u001B[0;34m(fun, has_aux, *primals)\u001B[0m\n\u001B[1;32m   2018\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_aux:\n\u001B[1;32m   2019\u001B[0m   flat_fun, out_tree \u001B[38;5;241m=\u001B[39m flatten_fun_nokwargs(fun, in_tree)\n\u001B[0;32m-> 2020\u001B[0m   out_primals, vjp \u001B[38;5;241m=\u001B[39m ad\u001B[38;5;241m.\u001B[39mvjp(flat_fun, primals_flat)\n\u001B[1;32m   2021\u001B[0m   out_tree \u001B[38;5;241m=\u001B[39m out_tree()\n\u001B[1;32m   2022\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/interpreters/ad.py:279\u001B[0m, in \u001B[0;36mvjp\u001B[0;34m(traceable, primals, has_aux)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvjp\u001B[39m(traceable: lu\u001B[38;5;241m.\u001B[39mWrappedFun, primals, has_aux\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    278\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_aux:\n\u001B[0;32m--> 279\u001B[0m     out_primals, pvals, jaxpr, consts \u001B[38;5;241m=\u001B[39m linearize(traceable, \u001B[38;5;241m*\u001B[39mprimals)\n\u001B[1;32m    280\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    281\u001B[0m     out_primals, pvals, jaxpr, consts, aux \u001B[38;5;241m=\u001B[39m linearize(traceable, \u001B[38;5;241m*\u001B[39mprimals, has_aux\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/interpreters/ad.py:264\u001B[0m, in \u001B[0;36mlinearize\u001B[0;34m(traceable, *primals, **kwargs)\u001B[0m\n\u001B[1;32m    262\u001B[0m _, in_tree \u001B[38;5;241m=\u001B[39m tree_flatten(((primals, primals), {}))\n\u001B[1;32m    263\u001B[0m jvpfun_flat, out_tree \u001B[38;5;241m=\u001B[39m flatten_fun(jvpfun, in_tree)\n\u001B[0;32m--> 264\u001B[0m jaxpr, out_pvals, consts \u001B[38;5;241m=\u001B[39m pe\u001B[38;5;241m.\u001B[39mtrace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n\u001B[1;32m    265\u001B[0m out_primals_pvals, out_tangents_pvals \u001B[38;5;241m=\u001B[39m tree_unflatten(out_tree(), out_pvals)\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;129;01mnot\u001B[39;00m out_primal_pval\u001B[38;5;241m.\u001B[39mis_known() \u001B[38;5;28;01mfor\u001B[39;00m out_primal_pval \u001B[38;5;129;01min\u001B[39;00m out_primals_pvals):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/profiler.py:334\u001B[0m, in \u001B[0;36mannotate_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    333\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m TraceAnnotation(name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdecorator_kwargs):\n\u001B[0;32m--> 334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    335\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m wrapper\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py:578\u001B[0m, in \u001B[0;36mtrace_to_jaxpr_nounits\u001B[0;34m(fun, pvals, instantiate)\u001B[0m\n\u001B[1;32m    576\u001B[0m fun \u001B[38;5;241m=\u001B[39m trace_to_subjaxpr_nounits(fun, trace, instantiate, fun\u001B[38;5;241m.\u001B[39mdebug_info)\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m core\u001B[38;5;241m.\u001B[39mset_current_trace(trace):\n\u001B[0;32m--> 578\u001B[0m   jaxpr, (out_pvals, consts, env) \u001B[38;5;241m=\u001B[39m fun\u001B[38;5;241m.\u001B[39mcall_wrapped(pvals)\n\u001B[1;32m    579\u001B[0m   \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m env\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m trace, fun\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/linear_util.py:210\u001B[0m, in \u001B[0;36mWrappedFun.call_wrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_wrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    209\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001B[39;00m\n\u001B[0;32m--> 210\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_transformed(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py:592\u001B[0m, in \u001B[0;36mtrace_to_subjaxpr_nounits\u001B[0;34m(f, trace, instantiate, debug_info, in_pvals)\u001B[0m\n\u001B[1;32m    584\u001B[0m \u001B[38;5;129m@lu\u001B[39m\u001B[38;5;241m.\u001B[39mtransformation2\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrace_to_subjaxpr_nounits\u001B[39m(\n\u001B[1;32m    586\u001B[0m     f: Callable,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    589\u001B[0m     debug_info: core\u001B[38;5;241m.\u001B[39mDebugInfo,\n\u001B[1;32m    590\u001B[0m     in_pvals: Sequence[PartialVal]):\n\u001B[1;32m    591\u001B[0m   \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(pv, PartialVal) \u001B[38;5;28;01mfor\u001B[39;00m pv \u001B[38;5;129;01min\u001B[39;00m in_pvals), in_pvals\n\u001B[0;32m--> 592\u001B[0m   out_tracers, jaxpr, out_consts, env \u001B[38;5;241m=\u001B[39m _trace_to_subjaxpr_nounits(\n\u001B[1;32m    593\u001B[0m       f, trace, instantiate, in_pvals, debug_info)\n\u001B[1;32m    594\u001B[0m   out_pvals \u001B[38;5;241m=\u001B[39m [t\u001B[38;5;241m.\u001B[39mpval \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m out_tracers]\n\u001B[1;32m    595\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m out_tracers\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/interpreters/partial_eval.py:625\u001B[0m, in \u001B[0;36m_trace_to_subjaxpr_nounits\u001B[0;34m(f, trace, instantiate, in_pvals, debug_info)\u001B[0m\n\u001B[1;32m    623\u001B[0m in_args \u001B[38;5;241m=\u001B[39m merge_lists(in_knowns, in_tracers, in_consts)\n\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m core\u001B[38;5;241m.\u001B[39mset_current_trace(trace):\n\u001B[0;32m--> 625\u001B[0m   ans \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;241m*\u001B[39min_args)\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ans, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)), (\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mans\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, core\u001B[38;5;241m.\u001B[39mTracer) \u001B[38;5;129;01mor\u001B[39;00m core\u001B[38;5;241m.\u001B[39mvalid_jaxtype(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m ans), (\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mans\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/api_util.py:73\u001B[0m, in \u001B[0;36mflatten_fun\u001B[0;34m(f, store, in_tree, *args_flat)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;129m@lu\u001B[39m\u001B[38;5;241m.\u001B[39mtransformation_with_aux2\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflatten_fun\u001B[39m(f: Callable, store: lu\u001B[38;5;241m.\u001B[39mStore,\n\u001B[1;32m     71\u001B[0m                 in_tree: PyTreeDef, \u001B[38;5;241m*\u001B[39margs_flat):\n\u001B[1;32m     72\u001B[0m   py_args, py_kwargs \u001B[38;5;241m=\u001B[39m tree_unflatten(in_tree, args_flat)\n\u001B[0;32m---> 73\u001B[0m   ans \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;241m*\u001B[39mpy_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpy_kwargs)\n\u001B[1;32m     74\u001B[0m   ans, out_tree \u001B[38;5;241m=\u001B[39m tree_flatten(ans)\n\u001B[1;32m     75\u001B[0m   store\u001B[38;5;241m.\u001B[39mstore(out_tree)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/interpreters/ad.py:80\u001B[0m, in \u001B[0;36mjvpfun\u001B[0;34m(f, instantiate, transform_stack, primals, tangents)\u001B[0m\n\u001B[1;32m     77\u001B[0m ctx \u001B[38;5;241m=\u001B[39m (source_info_util\u001B[38;5;241m.\u001B[39mtransform_name_stack(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjvp\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m transform_stack\n\u001B[1;32m     78\u001B[0m        \u001B[38;5;28;01melse\u001B[39;00m contextlib\u001B[38;5;241m.\u001B[39mnullcontext())\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ctx:\n\u001B[0;32m---> 80\u001B[0m   out_primals, out_tangents \u001B[38;5;241m=\u001B[39m f(tag, primals, tangents)\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(instantiate) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m     82\u001B[0m   instantiate \u001B[38;5;241m=\u001B[39m [instantiate] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(out_tangents)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/interpreters/ad.py:133\u001B[0m, in \u001B[0;36mjvp_subtrace\u001B[0;34m(f, tag, primals, tangents)\u001B[0m\n\u001B[1;32m    130\u001B[0m   in_tracers \u001B[38;5;241m=\u001B[39m [maybe_jvp_tracer(trace, x, t)\n\u001B[1;32m    131\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m x, t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(primals, tangents)]\n\u001B[1;32m    132\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m core\u001B[38;5;241m.\u001B[39mset_current_trace(trace):\n\u001B[0;32m--> 133\u001B[0m     ans \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;241m*\u001B[39min_tracers)\n\u001B[1;32m    134\u001B[0m   out \u001B[38;5;241m=\u001B[39m unzip2(\u001B[38;5;28mmap\u001B[39m(trace\u001B[38;5;241m.\u001B[39mto_primal_tangent_pair, ans))\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/api_util.py:90\u001B[0m, in \u001B[0;36mflatten_fun_nokwargs\u001B[0;34m(f, store, in_tree, *args_flat)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;129m@lu\u001B[39m\u001B[38;5;241m.\u001B[39mtransformation_with_aux2\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflatten_fun_nokwargs\u001B[39m(f: Callable, store: lu\u001B[38;5;241m.\u001B[39mStore,\n\u001B[1;32m     88\u001B[0m                          in_tree: PyTreeDef, \u001B[38;5;241m*\u001B[39margs_flat):\n\u001B[1;32m     89\u001B[0m   py_args \u001B[38;5;241m=\u001B[39m tree_unflatten(in_tree, args_flat)\n\u001B[0;32m---> 90\u001B[0m   ans \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;241m*\u001B[39mpy_args)\n\u001B[1;32m     91\u001B[0m   ans, out_tree \u001B[38;5;241m=\u001B[39m tree_flatten(ans)\n\u001B[1;32m     92\u001B[0m   store\u001B[38;5;241m.\u001B[39mstore(out_tree)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/api_util.py:284\u001B[0m, in \u001B[0;36m_argnums_partial\u001B[0;34m(_fun, _dyn_argnums, _fixed_args, *dyn_args, **kwargs)\u001B[0m\n\u001B[1;32m    282\u001B[0m args \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mnext\u001B[39m(fixed_args_)\u001B[38;5;241m.\u001B[39mval \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m sentinel \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m args]\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(fixed_args_, sentinel) \u001B[38;5;129;01mis\u001B[39;00m sentinel\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _fun(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/MagmaClustPy/lib/python3.12/site-packages/jax/_src/linear_util.py:388\u001B[0m, in \u001B[0;36m_get_result_paths_thunk\u001B[0;34m(_fun, _store, *args, **kwargs)\u001B[0m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;129m@transformation_with_aux2\u001B[39m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_result_paths_thunk\u001B[39m(_fun: Callable, _store: Store, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 388\u001B[0m   ans \u001B[38;5;241m=\u001B[39m _fun(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    389\u001B[0m   result_paths \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_clean_keystr_arg_names(path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m path, _ \u001B[38;5;129;01min\u001B[39;00m generate_key_paths(ans))\n\u001B[1;32m    390\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m _store:\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001B[39;00m\n\u001B[1;32m    392\u001B[0m     \u001B[38;5;66;03m# the bwd function in a custom_vjp\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[21], line 19\u001B[0m, in \u001B[0;36moptimise_hyperparameters.<locals>.mean_fun_wrapper\u001B[0;34m(kern)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean_fun_wrapper\u001B[39m(kern):\n\u001B[0;32m---> 19\u001B[0m \tres \u001B[38;5;241m=\u001B[39m magma_neg_likelihood(kern, all_inputs, post_mean, prior_mean, post_cov, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, nugget\u001B[38;5;241m=\u001B[39mnugget)\n\u001B[1;32m     20\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "Cell \u001B[0;32mIn[17], line 21\u001B[0m, in \u001B[0;36mmagma_neg_likelihood\u001B[0;34m(kernel, inputs, outputs, mean, mean_process_cov, mask, nugget)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# check if we need to vmap\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m---> 21\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m magma_neg_likelihood_on_cov(covar, outputs, mean, mean_process_cov, mask, nugget)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m     23\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m vmap(magma_neg_likelihood_on_cov, in_axes\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))(covar, outputs, mean,\n\u001B[1;32m     24\u001B[0m \t                                                                              mean_process_cov, mask, nugget)\n",
      "Cell \u001B[0;32mIn[16], line 35\u001B[0m, in \u001B[0;36mmagma_neg_likelihood_on_cov\u001B[0;34m(covar, outputs, mean, mean_process_cov, mask, nugget)\u001B[0m\n\u001B[1;32m     32\u001B[0m \tcorr_pad_correction \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     34\u001B[0m res \u001B[38;5;241m=\u001B[39m (multiv_neg_log_lik \u001B[38;5;241m-\u001B[39m nll_pad_correction) \u001B[38;5;241m+\u001B[39m (correction \u001B[38;5;241m-\u001B[39m corr_pad_correction)\n\u001B[0;32m---> 35\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_312_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_312_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1220\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread)\n",
      "File \u001B[0;32m~/Applications/DataSpell.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1235\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prediction",
   "id": "90de8c0b7b3db436"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:25.615529Z",
     "start_time": "2025-06-13T11:10:09.687606Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "66420b115921cdaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:25.617231Z",
     "start_time": "2025-06-13T11:10:09.739779Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "425f05bceebf211b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### End timer",
   "id": "476280134e1bc03d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:25.618344Z",
     "start_time": "2025-06-13T11:10:09.786181Z"
    }
   },
   "cell_type": "code",
   "source": "end = time.time()",
   "id": "692e7da8aadbbf8f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:25.618849Z",
     "start_time": "2025-06-13T11:10:09.838261Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Magma finished in {end - start:.2f}s\")",
   "id": "51950ffdb059c39d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magma finished in 19.15s\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "5e59da2023641cd6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Post-experiment sandbox",
   "id": "78271abd93646558"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:25.619116Z",
     "start_time": "2025-06-13T11:10:09.890781Z"
    }
   },
   "cell_type": "code",
   "source": "mean_kernel",
   "id": "ee9e36b771a9915e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEMagmaKernel(length_scale=0.9975587129592896, variance=6.232192516326904)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T11:14:25.619422Z",
     "start_time": "2025-06-13T11:10:09.936455Z"
    }
   },
   "cell_type": "code",
   "source": "task_kernel",
   "id": "a4c461b2f74af88d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoisySEMagmaKernel(length_scale=0.6336096525192261, variance=1.7702873945236206, noise=-1.7901536226272583)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "d9e61942954f1f43"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
